{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from src import config"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-16T09:00:57.107987Z",
     "start_time": "2024-07-16T09:00:56.794321Z"
    }
   },
   "id": "7c6fcef270881191",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "features_df = pd.read_pickle(os.path.join(config.classification_resource_dir, \"pairwise_sessions_features_df.pkl\"))\n",
    "labels_df = pd.read_pickle(os.path.join(config.classification_resource_dir, \"pairwise_sessions_labels_df.pkl\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-16T09:00:57.171046Z",
     "start_time": "2024-07-16T09:00:57.108965Z"
    }
   },
   "id": "9447514d4b35cb20",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "# Remove all the features that are contains 'Post' in their name\n",
    "features_df = features_df.loc[:, ~features_df.columns.str.contains('Post')]\n",
    "\n",
    "# Remove all the features that are contains 'SQRT' in their name\n",
    "features_df = features_df.loc[:, ~features_df.columns.str.contains('SQRT')]\n",
    "\n",
    "# Remove all the features that are start with 'Distance' in their name\n",
    "features_df = features_df.loc[:, ~features_df.columns.str.startswith('Distance')]\n",
    "\n",
    "# Remove all the features and keep only the ones that are contains 'DVA' in their name\n",
    "# features_df = features_df.loc[:, features_df.columns.str.startswith('DVA')]\n",
    "\n",
    "# Change the names of the features to be more readable-\n",
    "# remove the suffix '_Pre'\n",
    "features_df.columns = [col.replace('_Pre', '') for col in features_df.columns]\n",
    "\n",
    "# Take all the features that start with 'DVA', and add the suffix '_Distance' to them\n",
    "features_df.columns = [col + '_Distance' if col.startswith('DVA') else col for col in features_df.columns]\n",
    "features_df.columns = [col.replace('DVA_', '') for col in features_df.columns]\n",
    "\n",
    "# Replace '_' with ' ' (space)\n",
    "features_df.columns = [col.replace('_', ' ') for col in features_df.columns]\n",
    "\n",
    "features_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-16T09:00:57.233763Z",
     "start_time": "2024-07-16T09:00:57.172040Z"
    }
   },
   "id": "c2e51e57ddd33cf3",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Movie Gaze Counts In RoI Gaze Counts Out RoI Gaze In out RoI Ratio  \\\n",
       "0     19          -0.545455            0.212985             -0.642266   \n",
       "1     13                1.0           -0.130298                   1.0   \n",
       "2     32           0.929412           -0.019775              0.930808   \n",
       "3     18                NaN                 0.0                   NaN   \n",
       "4     16                0.6           -0.001181              0.600472   \n",
       "\n",
       "  Gaze Re Entries To RoI Count Gaze Re Entries To RoI Rate  \\\n",
       "0                         -0.8                        -0.8   \n",
       "1                          1.0                         1.0   \n",
       "2                        -0.75                       -0.75   \n",
       "3                          NaN                         NaN   \n",
       "4                          0.0                         0.0   \n",
       "\n",
       "  Gaze Mean Pupil Change On Event Fixations Counts In RoI  \\\n",
       "0                        2.903038                    -0.4   \n",
       "1                        0.316704                     1.0   \n",
       "2                       -0.003264                     1.0   \n",
       "3                        0.316337                     NaN   \n",
       "4                       -0.587239                     NaN   \n",
       "\n",
       "  Fixations Counts Out RoI Fixations In out RoI Ratio  ... Min Gaze Distance  \\\n",
       "0                 0.266667                      -0.56  ...          0.201053   \n",
       "1                 0.111111                        1.0  ...         -0.522926   \n",
       "2                 0.344828                        1.0  ...               1.0   \n",
       "3                 0.264706                        NaN  ...              -1.0   \n",
       "4                  -0.0625                        NaN  ...         -0.997524   \n",
       "\n",
       "  Sem Gaze Distance AUC Gaze Distance Mean Fixations Distance  \\\n",
       "0         -0.162551          0.303052                0.343968   \n",
       "1          0.356101         -0.064838               -0.043316   \n",
       "2         -0.352422          0.293406                0.245878   \n",
       "3          0.231838         -0.031344               -0.031364   \n",
       "4          0.038798          0.048274                0.057843   \n",
       "\n",
       "  Median Fixations Distance Std Fixations Distance Max Fixations Distance  \\\n",
       "0                  0.383264              -0.045712               0.037834   \n",
       "1                 -0.121632               0.307978               0.030588   \n",
       "2                  0.368718              -0.255102               0.032128   \n",
       "3                 -0.041235               0.146856               0.005983   \n",
       "4                  0.072574              -0.006875               0.038747   \n",
       "\n",
       "  Min Fixations Distance Sem Fixations Distance AUC Fixations Distance  \n",
       "0               0.781439              -0.100289               0.416861  \n",
       "1              -0.494648                0.20719               0.203598  \n",
       "2               0.114437              -0.407194               0.522389  \n",
       "3               0.047307               0.005072               0.240897  \n",
       "4              -0.015875               0.025051              -0.004943  \n",
       "\n",
       "[5 rows x 76 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Gaze Counts In RoI</th>\n",
       "      <th>Gaze Counts Out RoI</th>\n",
       "      <th>Gaze In out RoI Ratio</th>\n",
       "      <th>Gaze Re Entries To RoI Count</th>\n",
       "      <th>Gaze Re Entries To RoI Rate</th>\n",
       "      <th>Gaze Mean Pupil Change On Event</th>\n",
       "      <th>Fixations Counts In RoI</th>\n",
       "      <th>Fixations Counts Out RoI</th>\n",
       "      <th>Fixations In out RoI Ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>Min Gaze Distance</th>\n",
       "      <th>Sem Gaze Distance</th>\n",
       "      <th>AUC Gaze Distance</th>\n",
       "      <th>Mean Fixations Distance</th>\n",
       "      <th>Median Fixations Distance</th>\n",
       "      <th>Std Fixations Distance</th>\n",
       "      <th>Max Fixations Distance</th>\n",
       "      <th>Min Fixations Distance</th>\n",
       "      <th>Sem Fixations Distance</th>\n",
       "      <th>AUC Fixations Distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>-0.545455</td>\n",
       "      <td>0.212985</td>\n",
       "      <td>-0.642266</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>-0.8</td>\n",
       "      <td>2.903038</td>\n",
       "      <td>-0.4</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>-0.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0.201053</td>\n",
       "      <td>-0.162551</td>\n",
       "      <td>0.303052</td>\n",
       "      <td>0.343968</td>\n",
       "      <td>0.383264</td>\n",
       "      <td>-0.045712</td>\n",
       "      <td>0.037834</td>\n",
       "      <td>0.781439</td>\n",
       "      <td>-0.100289</td>\n",
       "      <td>0.416861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.130298</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.316704</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.522926</td>\n",
       "      <td>0.356101</td>\n",
       "      <td>-0.064838</td>\n",
       "      <td>-0.043316</td>\n",
       "      <td>-0.121632</td>\n",
       "      <td>0.307978</td>\n",
       "      <td>0.030588</td>\n",
       "      <td>-0.494648</td>\n",
       "      <td>0.20719</td>\n",
       "      <td>0.203598</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32</td>\n",
       "      <td>0.929412</td>\n",
       "      <td>-0.019775</td>\n",
       "      <td>0.930808</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.75</td>\n",
       "      <td>-0.003264</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.344828</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.352422</td>\n",
       "      <td>0.293406</td>\n",
       "      <td>0.245878</td>\n",
       "      <td>0.368718</td>\n",
       "      <td>-0.255102</td>\n",
       "      <td>0.032128</td>\n",
       "      <td>0.114437</td>\n",
       "      <td>-0.407194</td>\n",
       "      <td>0.522389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.316337</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.264706</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.231838</td>\n",
       "      <td>-0.031344</td>\n",
       "      <td>-0.031364</td>\n",
       "      <td>-0.041235</td>\n",
       "      <td>0.146856</td>\n",
       "      <td>0.005983</td>\n",
       "      <td>0.047307</td>\n",
       "      <td>0.005072</td>\n",
       "      <td>0.240897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.001181</td>\n",
       "      <td>0.600472</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.587239</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.0625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.997524</td>\n",
       "      <td>0.038798</td>\n",
       "      <td>0.048274</td>\n",
       "      <td>0.057843</td>\n",
       "      <td>0.072574</td>\n",
       "      <td>-0.006875</td>\n",
       "      <td>0.038747</td>\n",
       "      <td>-0.015875</td>\n",
       "      <td>0.025051</td>\n",
       "      <td>-0.004943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 76 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "features_df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-16T09:00:57.280836Z",
     "start_time": "2024-07-16T09:00:57.234730Z"
    }
   },
   "id": "26878df6c8e95564",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4352 entries, 0 to 4351\n",
      "Data columns (total 76 columns):\n",
      " #   Column                                    Non-Null Count  Dtype \n",
      "---  ------                                    --------------  ----- \n",
      " 0   Movie                                     4352 non-null   int8  \n",
      " 1   Gaze Counts In RoI                        3088 non-null   object\n",
      " 2   Gaze Counts Out RoI                       4352 non-null   object\n",
      " 3   Gaze In out RoI Ratio                     3088 non-null   object\n",
      " 4   Gaze Re Entries To RoI Count              3088 non-null   object\n",
      " 5   Gaze Re Entries To RoI Rate               3088 non-null   object\n",
      " 6   Gaze Mean Pupil Change On Event           4332 non-null   object\n",
      " 7   Fixations Counts In RoI                   2472 non-null   object\n",
      " 8   Fixations Counts Out RoI                  4342 non-null   object\n",
      " 9   Fixations In out RoI Ratio                2472 non-null   object\n",
      " 10  Fixations Re Entries To RoI Count         2472 non-null   object\n",
      " 11  Fixations Re Entries To RoI Rate          2472 non-null   object\n",
      " 12  onset Fixations First In RoI              2142 non-null   object\n",
      " 13  Duration Fixations First In RoI           2142 non-null   object\n",
      " 14  onset Mean Fixations In RoI               2142 non-null   object\n",
      " 15  onset Median Fixations In RoI             2142 non-null   object\n",
      " 16  onset Std Fixations In RoI                1572 non-null   object\n",
      " 17  onset Max Fixations In RoI                2142 non-null   object\n",
      " 18  Duration Max Fixations In RoI             2142 non-null   object\n",
      " 19  onset Min Fixations In RoI                2142 non-null   object\n",
      " 20  Duration Min Fixations In RoI             2142 non-null   object\n",
      " 21  onset Sem Fixations In RoI                1572 non-null   object\n",
      " 22  onset AUC Fixations In RoI                2142 non-null   object\n",
      " 23  Pupil radius Fixations First Diff         1922 non-null   object\n",
      " 24  Pupil radius Fixations ReEntry Mean Diff  1922 non-null   object\n",
      " 25  Fixations Mean Pupil Change On Event      4314 non-null   object\n",
      " 26  Saccades Start Counts In RoI              2438 non-null   object\n",
      " 27  Saccades Start Counts Out RoI             4342 non-null   object\n",
      " 28  Saccades Start In out RoI Ratio           2438 non-null   object\n",
      " 29  Saccades End Counts In RoI                2478 non-null   object\n",
      " 30  Saccades End Counts Out RoI               4342 non-null   object\n",
      " 31  Saccades End In out RoI Ratio             2478 non-null   object\n",
      " 32  last onset Saccades End First In RoI      2186 non-null   object\n",
      " 33  Duration Saccades End First In RoI        2186 non-null   object\n",
      " 34  vis angle Saccades End First In RoI       2186 non-null   object\n",
      " 35  peak velocity Saccades End First In RoI   2186 non-null   object\n",
      " 36  onset Mean Saccades Start In RoI          2072 non-null   object\n",
      " 37  onset Median Saccades Start In RoI        2072 non-null   object\n",
      " 38  onset Std Saccades Start In RoI           1494 non-null   object\n",
      " 39  onset Max Saccades Start In RoI           2072 non-null   object\n",
      " 40  Duration Max Saccades Start In RoI        2072 non-null   object\n",
      " 41  vis angle Max Saccades Start In RoI       2072 non-null   object\n",
      " 42  peak velocity Max Saccades Start In RoI   2072 non-null   object\n",
      " 43  onset Min Saccades Start In RoI           2072 non-null   object\n",
      " 44  Duration Min Saccades Start In RoI        2072 non-null   object\n",
      " 45  vis angle Min Saccades Start In RoI       2072 non-null   object\n",
      " 46  peak velocity Min Saccades Start In RoI   2072 non-null   object\n",
      " 47  onset Sem Saccades Start In RoI           1494 non-null   object\n",
      " 48  onset AUC Saccades Start In RoI           2072 non-null   object\n",
      " 49  last onset Mean Saccades End In RoI       2186 non-null   object\n",
      " 50  last onset Median Saccades End In RoI     2186 non-null   object\n",
      " 51  last onset Std Saccades End In RoI        1590 non-null   object\n",
      " 52  last onset Max Saccades End In RoI        2186 non-null   object\n",
      " 53  Duration Max Saccades End In RoI          2186 non-null   object\n",
      " 54  vis angle Max Saccades End In RoI         2186 non-null   object\n",
      " 55  peak velocity Max Saccades End In RoI     2186 non-null   object\n",
      " 56  last onset Min Saccades End In RoI        2186 non-null   object\n",
      " 57  Duration Min Saccades End In RoI          2186 non-null   object\n",
      " 58  vis angle Min Saccades End In RoI         2186 non-null   object\n",
      " 59  peak velocity Min Saccades End In RoI     2186 non-null   object\n",
      " 60  last onset Sem Saccades End In RoI        1590 non-null   object\n",
      " 61  last onset AUC Saccades End In RoI        2186 non-null   object\n",
      " 62  Mean Gaze Distance                        4352 non-null   object\n",
      " 63  Median Gaze Distance                      4352 non-null   object\n",
      " 64  Std Gaze Distance                         4352 non-null   object\n",
      " 65  Max Gaze Distance                         4352 non-null   object\n",
      " 66  Min Gaze Distance                         3268 non-null   object\n",
      " 67  Sem Gaze Distance                         4352 non-null   object\n",
      " 68  AUC Gaze Distance                         4352 non-null   object\n",
      " 69  Mean Fixations Distance                   4338 non-null   object\n",
      " 70  Median Fixations Distance                 4338 non-null   object\n",
      " 71  Std Fixations Distance                    4326 non-null   object\n",
      " 72  Max Fixations Distance                    4338 non-null   object\n",
      " 73  Min Fixations Distance                    4338 non-null   object\n",
      " 74  Sem Fixations Distance                    4326 non-null   object\n",
      " 75  AUC Fixations Distance                    4338 non-null   object\n",
      "dtypes: int8(1), object(75)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "labels_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-16T09:00:57.296362Z",
     "start_time": "2024-07-16T09:00:57.282842Z"
    }
   },
   "id": "e6f77a26d5f5ac9e",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           normalized_by_session_a\n",
       "series_id                         \n",
       "0                                1\n",
       "1                                0\n",
       "2                                0\n",
       "3                                0\n",
       "4                                1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>normalized_by_session_a</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>series_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "labels_df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-16T09:00:57.312365Z",
     "start_time": "2024-07-16T09:00:57.297361Z"
    }
   },
   "id": "55d5ddd75248e2af",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 4352 entries, 0 to 4351\n",
      "Data columns (total 1 columns):\n",
      " #   Column                   Non-Null Count  Dtype\n",
      "---  ------                   --------------  -----\n",
      " 0   normalized_by_session_a  4352 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 68.0 KB\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "source": [
    "Subject-wise or leave-one-subject-out (LOSO) cross-validation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25d46039db7b7165"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Leave-One-Subject-Out Cross-Validation (LOSO CV):\n",
    "- For each fold of the cross-validation, data from N-1 participants are used for training, and the data from the remaining participant is used for testing.\n",
    "- This process is repeated N times (for each participant), ensuring that each participant's data is used as a test set exactly once.\n",
    "- This method ensures that the model generalizes well across different participants."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "accfd74af5ba431"
  },
  {
   "cell_type": "code",
   "source": [
    "series_id_df = pd.read_pickle(os.path.join(config.classification_resource_dir, \"pairwise_sessions_series_id_df.pkl\"))\n",
    "\n",
    "# remove the corresponding rows from y_train\n",
    "series_id_df = series_id_df.loc[series_id_df.index.isin(features_df.index)]\n",
    "\n",
    "# Create a list of unique subject IDs\n",
    "subject_ids = series_id_df[config.SUBJECT].unique()\n",
    "\n",
    "# Order the list of subject IDs alphabetically\n",
    "subject_ids = np.sort(subject_ids)\n",
    "\n",
    "# Create groups of subject IDs\n",
    "groups = series_id_df[config.SUBJECT].values\n",
    "\n",
    "# Print the groups\n",
    "print(groups)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-16T09:00:57.327705Z",
     "start_time": "2024-07-16T09:00:57.314367Z"
    }
   },
   "id": "b00d1170f51a31c0",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DK47' 'AS20' 'TA01' ... 'KL89' 'BH27' 'HM02']\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from xgboost import XGBClassifier"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-16T09:00:57.375237Z",
     "start_time": "2024-07-16T09:00:57.328702Z"
    }
   },
   "id": "a01b0291073eaf6d",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "# XGBoost model\n",
    "\n",
    "def xgboost_model_searcher():\n",
    "    # Define the range of values for each hyperparameter\n",
    "    LEARNING_RATE = np.linspace(0.001, 0.5, 15)\n",
    "    MAX_DEPTH = range(2, 5)\n",
    "    N_ESTIMATORS = range(100, 150, 5)\n",
    "    \n",
    "    XGB_PARAM_GRID  = {\n",
    "        'learning_rate': LEARNING_RATE,\n",
    "        'max_depth': MAX_DEPTH,\n",
    "        'n_estimators': N_ESTIMATORS\n",
    "    }\n",
    "    \n",
    "    return GridSearchCV(estimator=XGBClassifier(), param_grid=XGB_PARAM_GRID, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-16T09:00:57.390770Z",
     "start_time": "2024-07-16T09:00:57.376235Z"
    }
   },
   "id": "ab4223a8bb4e06b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "classifiers = {\n",
    "    'XGBoost': xgboost_model_searcher()\n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-16T09:00:57.406774Z",
     "start_time": "2024-07-16T09:00:57.392758Z"
    }
   },
   "id": "f2b0e16b3549634f",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_model(model_name, y_test, y_pred):\n",
    "    # Evaluate the model using various metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    print(model_name)\n",
    "    # Print the evaluation metrics\n",
    "    print(\"Accuracy:\", round(accuracy, 2))\n",
    "    print(\"Precision:\", round(precision, 2))\n",
    "    print(\"Recall:\", round(recall, 2))\n",
    "    print(\"F1-score:\", round(f1, 2))\n",
    "    print(\"ROC-AUC score:\", round(roc_auc, 2))\n",
    "\n",
    "    # Compute the confusion matrix in average format (i.e., divide by the number of samples with the corresponding label)\n",
    "    confusion_mat = confusion_matrix(y_test, y_pred, normalize='true') * 100\n",
    "    # round the values in the confusion matrix\n",
    "    confusion_mat = np.round(confusion_mat).astype(int)\n",
    "    \n",
    "    # Create a heatmap visualization of the confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    sns.heatmap(confusion_mat, annot=True, cmap=\"Blues\", fmt=\"d\", ax=ax)\n",
    "\n",
    "    # Set the axis labels and title\n",
    "    ax.set_xlabel(\"Predicted Labels\")\n",
    "    ax.set_ylabel(\"True Labels\")\n",
    "    ax.set_title(\"Confusion Matrix\")\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()\n",
    "    \n",
    "    return confusion_mat"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-16T09:00:57.422288Z",
     "start_time": "2024-07-16T09:00:57.407763Z"
    }
   },
   "id": "fce6879d296a15ed",
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "import shap\n",
    "from sklearn.impute import KNNImputer\n",
    "import sys\n",
    "\n",
    "# Initialize LeaveOneSubjectOut cross-validator\n",
    "logo = LeaveOneGroupOut()\n",
    "\n",
    "# Function to perform LOSO CV and return average accuracy\n",
    "def evaluate_classifier(model_searcher, X, y, groups, name):\n",
    "    accuracies = {}\n",
    "    confusion_matricies = {}\n",
    "    confidence_intervals = {}\n",
    "    models = {}\n",
    "    roc_auc_curves = {}\n",
    "    shap_values_dict = {}\n",
    "\n",
    "    for train_index, test_index in logo.split(X, y, groups):\n",
    "        # Extract indices for training and testing data for each participant\n",
    "        X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "        y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "        # fill inf values with the maximum int, and -inf with the minimum int\n",
    "        X_train = X_train.replace(np.inf, sys.maxsize)\n",
    "        X_train = X_train.replace(-np.inf, -sys.maxsize)\n",
    "        X_test = X_test.replace(np.inf, sys.maxsize)\n",
    "        X_test = X_test.replace(-np.inf, -sys.maxsize)\n",
    "\n",
    "        # Create the imputer\n",
    "        imputer = KNNImputer(n_neighbors=7)\n",
    "        # Apply the imputer to the DataFrame\n",
    "        X_train = imputer.fit_transform(X_train)\n",
    "        X_test = imputer.transform(X_test)\n",
    "\n",
    "        # Scale the data\n",
    "        # Create separate StandardScaler instances\n",
    "        # scaler_x = StandardScaler()\n",
    "        # # Fit on Training Data (!)\n",
    "        # scaler_x.fit(X_train)\n",
    "        # # Transform both training and testing data\n",
    "        # X_train_scaled = scaler_x.transform(X_train)\n",
    "        # X_test_scaled = scaler_x.transform(X_test)\n",
    "        # y_train = y_train.values.reshape(-1, 1).flatten()\n",
    "        # y_test = y_test.values.reshape(-1, 1).flatten()\n",
    "        # X_train_scaled = X_train_scaled\n",
    "        # X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "        X_test_scaled = X_test\n",
    "        X_train_scaled = X_train\n",
    "\n",
    "        model_searcher.fit(X_train_scaled, y_train)\n",
    "        clf = model_searcher.best_estimator_\n",
    "\n",
    "        # Fit the classifier\n",
    "        clf.fit(X_train_scaled, y_train)\n",
    "        y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        # Store the results for this fold using subject name as key\n",
    "        subject_name = groups[test_index[0]]\n",
    "        accuracies[subject_name] = acc\n",
    "        conf_mat = evaluate_model(f\"{name} on {subject_name}\", y_test, y_pred)\n",
    "        confusion_matricies[subject_name] = conf_mat\n",
    "        models[subject_name] = clf\n",
    "        confidence_intervals[subject_name] = (acc - 1.96 * np.sqrt(acc * (1 - acc) / len(y_test)), acc + 1.96 * np.sqrt(acc * (1 - acc) / len(y_test)))\n",
    "        roc_auc_curves[subject_name] = y_test, clf.predict_proba(X_test_scaled)[:, 1]\n",
    "\n",
    "        # Calculate Shap values\n",
    "        explainer = shap.TreeExplainer(clf)\n",
    "        shap_values = explainer.shap_values(X_test_scaled)\n",
    "        shap_values_dict[subject_name] = shap_values\n",
    "        \n",
    "    # return all the computed dictionaries\n",
    "    return accuracies, confusion_matricies, confidence_intervals, models, roc_auc_curves, shap_values_dict\n",
    "\n",
    "# Evaluate each classifier\n",
    "results = {}\n",
    "for name, clf in classifiers.items():\n",
    "    acc, confusion_matricies, confidence_intervals, models, roc_auc_curves, shap_values_dict = evaluate_classifier(clf, features_df, labels_df, groups, name)\n",
    "    avg_confusion_matrix = np.mean(list(confusion_matricies.values()), axis=0)\n",
    "    avg_acc = np.mean(list(acc.values())) \n",
    "    sd_acc = np.std(list(acc.values()))\n",
    "\n",
    "    results[name] = avg_acc, avg_confusion_matrix, acc, confusion_matricies, confidence_intervals, models, roc_auc_curves, shap_values_dict, sd_acc\n",
    "    print(f\"Average accuracy of {name}: {avg_acc:.4f}\")\n",
    "    print(f\"Average confusion matrix of {name}: {avg_confusion_matrix}\")\n",
    "\n",
    "# Decision-making (choose the classifier with the highest average accuracy)\n",
    "best_classifier_name = max(results, key=lambda k: results[k][0])\n",
    "print(f\"\\nThe best classifier is: {best_classifier_name} with accuracy: {results[best_classifier_name][0]:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-07-16T09:00:57.425284Z"
    }
   },
   "id": "38aa660c534b5698",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot the average confusion matrix\n",
    "# round the values in the confusion matrix\n",
    "avg_confusion_matrix_round = np.round(results[best_classifier_name][1]).astype(int)\n",
    "\n",
    "# Create a heatmap visualization of the confusion matrix\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "# the color range should start at 0 and end at the maximum value in the confusion matrix\n",
    "sns.heatmap(avg_confusion_matrix_round, annot=True, cmap=\"gray\", fmt=\"d\", ax=ax, vmin=0, vmax=100)\n",
    "\n",
    "# Set the axis values- replace 0 with 1st viewing and 1 with 2nd viewing\n",
    "ax.set_xticklabels(['1st', '2nd'])\n",
    "ax.set_yticklabels(['1st', '2nd'])\n",
    "\n",
    "\n",
    "# Set the axis labels and title\n",
    "ax.set_xlabel(\"Predicted Labels\")\n",
    "ax.set_ylabel(\"True Labels\")\n",
    "ax.set_title(\"Average Confusion Matrix (%)\\n\")\n",
    "\n",
    "# Style\n",
    "# Make the fonts visible in the plot\n",
    "plt.rcParams.update({'font.size': 30})\n",
    "# Make the tick labels of the heatmap visible\n",
    "for tick in ax.get_xticklabels():\n",
    "    tick.set_visible(True)\n",
    "for tick in ax.get_yticklabels():\n",
    "    tick.set_visible(True)\n",
    "    \n",
    "# Save the plot\n",
    "plt.savefig(os.path.join(config.classification_resource_dir, \"confusion_matrix.svg\"), bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Print the average correct classification rate for each class and the standard deviation\n",
    "print(f\"Average correct classification rate for 1st viewing: {avg_confusion_matrix_round[0, 0]:.2f}% ± {np.std([conf_mat[0, 0] for conf_mat in results[best_classifier_name][3].values()]):.2f}%\")\n",
    "print(f\"Average correct classification rate for 2nd viewing: {avg_confusion_matrix_round[1, 1]:.2f}% ± {np.std([conf_mat[1, 1] for conf_mat in results[best_classifier_name][3].values()]):.2f}%\")  "
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "dc800bfcd1e7394",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculating ROC AUC for each participant (fold)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b6737af3fee693d"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "roc_auc_curves = results[best_classifier_name][6]\n",
    "\n",
    "# Plot ROC curve for each participant\n",
    "fig, ax = plt.subplots(figsize=(16, 16))\n",
    "\n",
    "# For each fold calculate ROC curve and ROC area\n",
    "for subject_name, (y_test, y_pred) in roc_auc_curves.items():\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    # Plot ROC curve with transparency\n",
    "    ax.plot(fpr, tpr, lw=2, alpha=0.3, label=f'ROC curve of {subject_name} (area = {roc_auc:.2f})')\n",
    "    \n",
    "\n",
    "y_test, y_pred = np.concatenate([y_test for y_test, y_pred in roc_auc_curves.values()]), np.concatenate([y_pred for y_test, y_pred in roc_auc_curves.values()])\n",
    "# Plot ROC curve for average classifier with error bars representing 95% confidence intervals\n",
    "fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "print(y_pred)\n",
    "# ROC AUC average Standard Deviation\n",
    "sd_auc = np.std(tpr)\n",
    " \n",
    "ax.plot(fpr, tpr, color='black', lw=2, label=f'ROC curve of average classifier (area = {roc_auc:.2f})')\n",
    "\n",
    "# Plot ROC curve for random classifier\n",
    "ax.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--', label='Random Classifier')\n",
    "\n",
    "# Set the limits of the plot to include both curves, don't show 0.0 twice on the x-axis and the y-axis\n",
    "ax.set_xlim([0.000001, 1.0])\n",
    "ax.set_ylim([0.0, 1.05])\n",
    "\n",
    "# Increase font size\n",
    "plt.rcParams.update({'font.size': 35})\n",
    "\n",
    "# Set the axis labels and title\n",
    "ax.set_xlabel('False Positive Rate')\n",
    "ax.set_ylabel('True Positive Rate')\n",
    "ax.set_title('Receiver Operating Characteristic (ROC) Curve')\n",
    "# Increse xlabel and ylabel font size\n",
    "ax.xaxis.label.set_size(50)\n",
    "ax.yaxis.label.set_size(50)\n",
    "\n",
    "# Transparent background\n",
    "ax.patch.set_alpha(0.0)\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(os.path.join(config.classification_resource_dir, \"roc_auc.svg\"), bbox_inches='tight')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Print the average ROC AUC with standard deviation\n",
    "print(f\"Average ROC AUC: {roc_auc:.4f} ± {sd_auc:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "7df50c368e1e6d37",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from scipy.stats import ttest_1samp\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "roc_auc_curves = results[best_classifier_name][6]\n",
    "roc_auc_scores = [roc_auc_score(y_test, y_pred) for y_test, y_pred in roc_auc_curves.values()]\n",
    "\n",
    "# Print the average ROC AUC with standard deviation\n",
    "print(f\" ROC AUC Scores: {roc_auc_scores}, len: {len(roc_auc_scores)}\")\n",
    "      \n",
    "# Perform 1-sample t-test\n",
    "t_stat, p_value = ttest_1samp(roc_auc_scores, 0.5)\n",
    "\n",
    "# Print the results\n",
    "print(f\"1-sample t-test: t({len(roc_auc_scores) - 1}) = {t_stat:.4f}, p = {p_value}\")"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "15c49cc7d6fa64ce",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Calculating Performance Across Participants (Subject-wise)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "56894f0e73d1683a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The Y-axis can represent the accuracy for each participant, i.e., the percentage of correct classifications. This is the most direct measure of classifier performance and would be readily interpretable by most readers. We can use error bars to represent confidence intervals for each participant's accuracy."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2028c7c1abc7daf2"
  },
  {
   "cell_type": "code",
   "source": [
    "acc = results[best_classifier_name][2]\n",
    "confidence_intervals = results[best_classifier_name][4]\n",
    "avg_acc = results[best_classifier_name][0]\n",
    "\n",
    "# Plot the accuracy for each participant with wide error bars representing 95% confidence intervals for each participant\n",
    "fig, ax = plt.subplots(figsize=(16, 8))\n",
    "# Sort the accuracies dictionary by value (accuracy) and plot the values\n",
    "# Color the bars according to the confidence intervals in grays\n",
    "ax.bar(sorted(acc, key=acc.get), [acc[key] for key in sorted(acc, key=acc.get)], color='gray', yerr=[[acc[key] - confidence_intervals[key][0] for key in sorted(acc, key=acc.get)], [confidence_intervals[key][1] - acc[key] for key in sorted(acc, key=acc.get)]], capsize=10)\n",
    "ax.set_xlabel(\"Subject\")\n",
    "ax.set_ylabel(\"Accuracy\")\n",
    "ax.set_title(\"Accuracy for each subject (model)\")\n",
    "# remove the ticks from the x-axis\n",
    "ax.set_xticks([])\n",
    "\n",
    "# Add a horizontal dashed line representing the average accuracy across participants\n",
    "ax.axhline(y=avg_acc, color='r', linestyle='-')\n",
    "# Add horizontal lines representing the chance level accuracy (50%) and the perfect accuracy (100%)\n",
    "ax.axhline(y=0.5, color='gray', linestyle='--', label='Chance level')\n",
    "# Add label for the chance level accuracy\n",
    "# ax.text(0, 0.5, 'Chance level', ha='left', va='center', transform=ax.get_yaxis_transform(), color='gray', alpha=0.5, fontsize=30)\n",
    "\n",
    "# Increase font size\n",
    "plt.rcParams.update({'font.size': 40})\n",
    "# Save the plot\n",
    "plt.savefig(os.path.join(config.classification_resource_dir, \"accuracy_distribution.svg\"), bbox_inches='tight')\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "# Print how many participants have accuracy above the chance level\n",
    "above_chance = sum(acc > 0.5 for acc in acc.values())\n",
    "print(f\"Participants with accuracy above chance level: {above_chance}/{len(acc)}\")\n",
    "\n",
    "# Print the average accuracy with standard deviation\n",
    "print(f\"Average accuracy: {avg_acc:.4f} ± {results[best_classifier_name][8]:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "bf1ef32c0f9cef59",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Take the best model and train it on the whole dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b17995bbda6815ae"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best model is SVM, so we will train it on the whole dataset, using the average hyperparameters from the LOSO CV"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13859c97e2d2678c"
  },
  {
   "cell_type": "code",
   "source": [
    "# Get the best model\n",
    "best_model = results[best_classifier_name][5]\n",
    "\n",
    "# Go over all the models and average the hyperparameters\n",
    "best_model_params = {}\n",
    "for model in best_model.values():\n",
    "    for param, value in model.get_params().items():\n",
    "        # If parameter is numeric, add it to the dictionary\n",
    "        if isinstance(value, (int, float)):\n",
    "            # if the parameter is already in the dictionary, append the value to the list\n",
    "            if param in best_model_params:\n",
    "                best_model_params[param].append(value)\n",
    "            else:\n",
    "                best_model_params[param] = [value]\n",
    "for param, value in best_model_params.items():\n",
    "    best_model_params[param] = np.mean(value)\n",
    "\n",
    "best_model_params"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "5ac6c97b3f2316e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Train the best model on the whole dataset using the average hyperparameters\n",
    "X_train = features_df\n",
    "y_train = labels_df\n",
    "\n",
    "# fill inf values with the mean of the column\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
    "X_train = X_train.fillna(X_train.mean()) # fill missing values with the mean of the column or zero ? features_df.mean()\n",
    "\n",
    "# Scale the data\n",
    "# Create separate StandardScaler instances\n",
    "scaler_x = StandardScaler()\n",
    "# Fit on Training Data (!)\n",
    "scaler_x.fit(X_train.values)\n",
    "# Transform both training and testing data\n",
    "X_train_scaled = scaler_x.transform(X_train.values)\n",
    "y_train = y_train.values.reshape(-1, 1).flatten()\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "\n",
    "# SVM\n",
    "# Train final model with best hyperparameters\n",
    "xgb = XGBClassifier(learning_rate=0.1426, max_depth=2, n_estimators=124)\n",
    "xgb.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = xgb.predict_proba(X_train_scaled)[:, 1]\n",
    "# acc = accuracy_score(y_train, y_pred)  \n",
    "# conf_mat = evaluate_model(f\"xgb on whole dataset\", y_train, y_pred)\n"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "d48c6201f66b668f",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot ROC curve"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "62437ee3c8946a4e"
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr, tpr, _ = roc_curve(y_train, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.plot(fpr, tpr, color='darkorange', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    " \n",
    "# Plot ROC curve for random classifier\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--', label='Random Classifier')\n",
    "\n",
    "# Set the limits of the plot to include both curves\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "\n",
    "# Set the axis labels and title\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "78e9eb854f51a0c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from xgboost import plot_tree\n",
    "\n",
    "# plot single tree from the model Use visible format\n",
    "plot_tree(xgb, num_trees=0, rankdir='LR')\n"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "1fd605eb117ee692",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Feature importance and SHAP values for the best model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f75896861ac1ae36"
  },
  {
   "cell_type": "code",
   "source": [
    "import shap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Create object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(xgb)\n",
    "\n",
    "# Calculate Shap values\n",
    "shap_values = explainer.shap_values(X_train_scaled)\n",
    "\n",
    "# Increase font size\n",
    "plt.rcParams.update({'font.size': 30})\n",
    "\n",
    "# Plot summary plot (feature importance) with the top 15 features in gray color\n",
    "shap.summary_plot(shap_values, X_train_scaled, plot_type=\"bar\", max_display=5, color='gray')\n",
    "\n",
    "# mark the features that has the suffix '_Distance' in their name with astrisk\n",
    "# X_train_scaled.columns = ['* ' + col if col.endswith('Distance') else col for col in X_train_scaled.columns]\n",
    "\n",
    "\n",
    "# Plot summary plot with the top 21 features\n",
    "shap.summary_plot(shap_values, X_train_scaled, max_display=21, color='gray', show=False)\n",
    "# Increase font size of the feature names\n",
    "plt.yticks(fontsize=20)\n",
    "plt.xticks(fontsize=15)\n",
    "# Add the y-axis that highlights that the features are sorted by their importance\n",
    "plt.ylabel(\"Sorted by importance\", fontsize=30)\n",
    "# centered the y-axis label \n",
    "\n",
    "plt.xlabel(\"SHAP value\", fontsize=20)\n",
    "# add x-axis values\n",
    "plt.xlim(-2, 2)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(config.classification_resource_dir, \"shap_values_summary.svg\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(os.path.join(config.classification_resource_dir, \"shap_values.png\"))"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "d6a3d993b03665b3",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# After calculating SHAP values, aggregate them to measure the overall impact of each feature across all samples. You can then create a global feature importance plot, which ranks features by their importance (i.e., the sum of the absolute SHAP values for each feature across all samples). This plot will clearly show the Mean Gaze Distance as the most significant feature if its SHAP values are consistently higher than those of other features.\n",
    "\n",
    "# Calculate the global feature importance\n",
    "global_importance = np.abs(shap_values).mean(axis=0)\n",
    "\n",
    "# Create a DataFrame to store the global feature importance\n",
    "global_importance_df = pd.DataFrame(global_importance, index=X_train_scaled.columns, columns=[\"Importance\"])\n",
    "\n",
    "# Sort the features by their importance\n",
    "global_importance_df = global_importance_df.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Plot the global feature importance\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.barh(global_importance_df.index, global_importance_df[\"Importance\"], color='gray')\n",
    "plt.xlabel(\"Mean |SHAP value|\")\n",
    "plt.title(\"Global Feature Importance\")\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "a298d7a75d20f655",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# # Perform statistical tests to compare the Mean Gaze Distance with other features\n",
    "# import numpy as np\n",
    "# import scipy.stats as stats\n",
    "# import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# \n",
    "# # Assuming `shap_values` as a DataFrame with features as columns\n",
    "# mean_gaze_distance_shap = global_importance_df.loc['Mean Gaze Distance', 'Importance']\n",
    "# other_features_shap = global_importance_df.drop('Mean Gaze Distance')['Importance']\n",
    "# \n",
    "# # Wilcoxon Signed-Rank Test for each feature against Mean Gaze Distance\n",
    "# p_values = {feature: stats.wilcoxon(mean_gaze_distance_shap, global_importance_df.loc[feature, 'Importance'])[1] for feature in other_features_shap.index}\n",
    "# \n",
    "# # Adjust p-values for multiple comparisons, if necessary\n",
    "# adjusted_p_values = {feature: val * len(p_values) for feature, val in p_values.items()}  # Example of Bonferroni correction\n",
    "# \n",
    "# # Visualization\n",
    "# sns.boxplot(data=shap_values[['Mean Gaze Distance'] + list(other_features_shap.columns)])\n",
    "# plt.xticks(rotation=45)  \n",
    "# plt.title(\"SHAP Values Distribution for Mean Gaze Distance vs Other Features\")\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# \n",
    "# # Print adjusted p-values\n",
    "# for feature, p_val in adjusted_p_values.items():\n",
    "#     print(f\"{feature}: {p_val}\")\n",
    "#     "
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "807679b1762af859",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "681f4f51e8ba9b56",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Study example use cases using shap force plots"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5fa1f3ed1815368"
  },
  {
   "cell_type": "code",
   "source": [
    "# # Select a specific instance (e.g., the first instance)\n",
    "# instance_index = 1\n",
    "# shap_values_instance = shap_values[instance_index]\n",
    "# X_test_instance = X_train_scaled.iloc[instance_index]\n",
    "# \n",
    "# # Get the indices of the features with the top 5 absolute SHAP values\n",
    "# top_indices = np.argsort(np.abs(shap_values_instance))[-5:]\n",
    "# \n",
    "# # Create new SHAP values and feature arrays that only include these top 5 features\n",
    "# shap_values_top = shap_values_instance[top_indices]\n",
    "# X_test_top = X_test_instance.iloc[top_indices]\n",
    "# \n",
    "# # Plot the SHAP force plot for the instance\n",
    "# shap.force_plot(explainer.expected_value, shap_values_top, X_test_top, matplotlib=True)"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "f939da4871cf7f37",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# # Select a specific instance (e.g., the first instance)\n",
    "# instance_index = 18\n",
    "# \n",
    "# shap_values_instance = shap_values[instance_index]\n",
    "# X_test_instance = X_train_scaled.iloc[instance_index]\n",
    "# \n",
    "# # Get the indices of the features with the top 10 absolute SHAP values\n",
    "# top_indices = np.argsort(np.abs(shap_values_instance))[:]\n",
    "# \n",
    "# # Create new SHAP values and feature arrays that only include these top 10 features\n",
    "# shap_values_top = shap_values_instance[top_indices]\n",
    "# X_test_top = X_test_instance.iloc[top_indices]\n",
    "# \n",
    "# # Plot the SHAP waterfall plot for the instance\n",
    "# plt.figure(figsize=(10, 20))\n",
    "# shap.plots.waterfall(shap.Explanation(values=shap_values_top, base_values=explainer.expected_value, data=X_test_top), max_display=7, show=False)\n",
    "# \n",
    "# # Increase font size\n",
    "# plt.rcParams.update({'font.size': 50})\n",
    "# plt.xticks(fontsize=15)\n",
    "# plt.yticks(fontsize=25)\n",
    "# # plt.tight_layout()\n",
    "# \n",
    "# # Save the plot\n",
    "# plt.savefig(os.path.join(config.classification_resource_dir, \"shap_waterfall.svg\"))\n",
    "# \n",
    "# # print the true label of the instance\n",
    "# print(f\"True label: {y_train[instance_index]}\")\n",
    "# # print the pred label of the instance\n",
    "# print(f\"Pred label: {xgb.predict(X_test_instance.values.reshape(1, -1))[0]}\")"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "6e3e12b84dc38d5c",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# from xgboost import plot_tree\n",
    "# \n",
    "# # plot single tree from the model big size\n",
    "# fig = plt.figure(figsize=(20, 20))\n",
    "# plot_tree(xgb, num_trees=0, rankdir='LR', ax=plt.gca())"
   ],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "4f31cc4da5033b13",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "id": "3c09df5636b05593",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
