{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:48.604200800Z",
     "start_time": "2023-08-14T12:29:48.295458200Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import os\n",
    "from src import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "features_df = pd.read_pickle(os.path.join(config.classification_resource_dir, \"memory_features_df.pkl\"))\n",
    "labels_df = pd.read_pickle(os.path.join(config.classification_resource_dir, \"memory_labels_df.pkl\"))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:48.619163300Z",
     "start_time": "2023-08-14T12:29:48.606199300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "   Blinks_Per_Minute  Blinks_Duration_Mean  Blinks_Duration_Median  \\\n0          12.342857            132.000000                   129.0   \n1                NaN                   NaN                     NaN   \n2          27.692308            130.000000                    86.0   \n3          12.378223             72.666667                    66.0   \n4          14.400000             79.000000                    80.0   \n\n   Blink_Variability  Blinks_Duration_Min  Blinks_Duration_Max  \\\n0          67.549981                 66.0                201.0   \n1                NaN                  NaN                  NaN   \n2         104.115321                 64.0                312.0   \n3          24.684678                 52.0                100.0   \n4          26.514147                 52.0                105.0   \n\n   Fixations_Count  Fixations_Rate  Fixations_Duration_Mean  \\\n0             35.0        2.400000               333.771429   \n1             46.0        3.154286               284.608696   \n2             30.0        2.769231               321.066667   \n3             52.0        3.575931               244.423077   \n4             25.0        2.000000               308.080000   \n\n   Fixations_Duration_Median  ...  DVA_Min_Gaze_Pre  DVA_Sem_Gaze_Pre  \\\n0                      275.0  ...          9.485436          0.114942   \n1                      267.0  ...          2.614537          0.113426   \n2                      264.0  ...          5.844040          0.128652   \n3                      217.0  ...         11.783918          0.042936   \n4                      223.0  ...          0.581440          0.076724   \n\n   DVA_AUC_Gaze_Pre  DVA_Mean_Fixations_Pre  DVA_Median_Fixations_Pre  \\\n0      52474.278127               19.743823                 24.670071   \n1      62010.907977               19.295206                 22.554525   \n2      36331.111637               16.405096                 16.357059   \n3      62956.761877               19.795590                 20.467621   \n4      64937.572461               15.083811                 16.300744   \n\n   DVA_Std_Fixations_Pre  DVA_Max_Fixations_Pre  DVA_Min_Fixations_Pre  \\\n0               6.053553              25.457728               9.789465   \n1               6.835452              25.391660               3.181130   \n2               6.786038              25.893978               6.629466   \n3               2.385218              24.389404              16.085974   \n4               5.101190              22.310018               1.558471   \n\n   DVA_Sem_Fixations_Pre  DVA_AUC_Fixations_Pre  \n0               1.563021             296.157339  \n1               1.528453             385.904129  \n2               1.813645             229.671346  \n3               0.459035             534.480926  \n4               1.087577             331.843843  \n\n[5 rows x 102 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Blinks_Per_Minute</th>\n      <th>Blinks_Duration_Mean</th>\n      <th>Blinks_Duration_Median</th>\n      <th>Blink_Variability</th>\n      <th>Blinks_Duration_Min</th>\n      <th>Blinks_Duration_Max</th>\n      <th>Fixations_Count</th>\n      <th>Fixations_Rate</th>\n      <th>Fixations_Duration_Mean</th>\n      <th>Fixations_Duration_Median</th>\n      <th>...</th>\n      <th>DVA_Min_Gaze_Pre</th>\n      <th>DVA_Sem_Gaze_Pre</th>\n      <th>DVA_AUC_Gaze_Pre</th>\n      <th>DVA_Mean_Fixations_Pre</th>\n      <th>DVA_Median_Fixations_Pre</th>\n      <th>DVA_Std_Fixations_Pre</th>\n      <th>DVA_Max_Fixations_Pre</th>\n      <th>DVA_Min_Fixations_Pre</th>\n      <th>DVA_Sem_Fixations_Pre</th>\n      <th>DVA_AUC_Fixations_Pre</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12.342857</td>\n      <td>132.000000</td>\n      <td>129.0</td>\n      <td>67.549981</td>\n      <td>66.0</td>\n      <td>201.0</td>\n      <td>35.0</td>\n      <td>2.400000</td>\n      <td>333.771429</td>\n      <td>275.0</td>\n      <td>...</td>\n      <td>9.485436</td>\n      <td>0.114942</td>\n      <td>52474.278127</td>\n      <td>19.743823</td>\n      <td>24.670071</td>\n      <td>6.053553</td>\n      <td>25.457728</td>\n      <td>9.789465</td>\n      <td>1.563021</td>\n      <td>296.157339</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>46.0</td>\n      <td>3.154286</td>\n      <td>284.608696</td>\n      <td>267.0</td>\n      <td>...</td>\n      <td>2.614537</td>\n      <td>0.113426</td>\n      <td>62010.907977</td>\n      <td>19.295206</td>\n      <td>22.554525</td>\n      <td>6.835452</td>\n      <td>25.391660</td>\n      <td>3.181130</td>\n      <td>1.528453</td>\n      <td>385.904129</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>27.692308</td>\n      <td>130.000000</td>\n      <td>86.0</td>\n      <td>104.115321</td>\n      <td>64.0</td>\n      <td>312.0</td>\n      <td>30.0</td>\n      <td>2.769231</td>\n      <td>321.066667</td>\n      <td>264.0</td>\n      <td>...</td>\n      <td>5.844040</td>\n      <td>0.128652</td>\n      <td>36331.111637</td>\n      <td>16.405096</td>\n      <td>16.357059</td>\n      <td>6.786038</td>\n      <td>25.893978</td>\n      <td>6.629466</td>\n      <td>1.813645</td>\n      <td>229.671346</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>12.378223</td>\n      <td>72.666667</td>\n      <td>66.0</td>\n      <td>24.684678</td>\n      <td>52.0</td>\n      <td>100.0</td>\n      <td>52.0</td>\n      <td>3.575931</td>\n      <td>244.423077</td>\n      <td>217.0</td>\n      <td>...</td>\n      <td>11.783918</td>\n      <td>0.042936</td>\n      <td>62956.761877</td>\n      <td>19.795590</td>\n      <td>20.467621</td>\n      <td>2.385218</td>\n      <td>24.389404</td>\n      <td>16.085974</td>\n      <td>0.459035</td>\n      <td>534.480926</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14.400000</td>\n      <td>79.000000</td>\n      <td>80.0</td>\n      <td>26.514147</td>\n      <td>52.0</td>\n      <td>105.0</td>\n      <td>25.0</td>\n      <td>2.000000</td>\n      <td>308.080000</td>\n      <td>223.0</td>\n      <td>...</td>\n      <td>0.581440</td>\n      <td>0.076724</td>\n      <td>64937.572461</td>\n      <td>15.083811</td>\n      <td>16.300744</td>\n      <td>5.101190</td>\n      <td>22.310018</td>\n      <td>1.558471</td>\n      <td>1.087577</td>\n      <td>331.843843</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 102 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove all the features that contains 'Post' in their name\n",
    "features_df = features_df.loc[:, ~features_df.columns.str.contains('Post')]\n",
    "features_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:48.651075100Z",
     "start_time": "2023-08-14T12:29:48.625145200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2040 entries, 0 to 2039\n",
      "Columns: 102 entries, Blinks_Per_Minute to DVA_AUC_Fixations_Pre\n",
      "dtypes: float64(102)\n",
      "memory usage: 1.6 MB\n"
     ]
    }
   ],
   "source": [
    "features_df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:48.674018400Z",
     "start_time": "2023-08-14T12:29:48.657060900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "           mem\nseries_id     \n0            1\n1            1\n2            1\n3            1\n4            1",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>mem</th>\n    </tr>\n    <tr>\n      <th>series_id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:48.706459300Z",
     "start_time": "2023-08-14T12:29:48.670026800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2040 entries, 0 to 2039\n",
      "Data columns (total 1 columns):\n",
      " #   Column  Non-Null Count  Dtype\n",
      "---  ------  --------------  -----\n",
      " 0   mem     2040 non-null   int64\n",
      "dtypes: int64(1)\n",
      "memory usage: 31.9 KB\n"
     ]
    }
   ],
   "source": [
    "labels_df.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:48.719417800Z",
     "start_time": "2023-08-14T12:29:48.681997300Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Cleaning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "how many missing values are there in each column? show the top 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "Pupil radius_Fixations_ReEntry_Mean_Diff_Pre    460\nPupil radius_Fixations_First_Diff_Pre           460\nBlinks_Duration_Max                             397\nBlinks_Duration_Mean                            397\nBlinks_Per_Minute                               397\nBlinks_Duration_Min                             397\nBlinks_Duration_Median                          397\nBlink_Variability                               397\nonset_Mean_Saccades_Start_In_RoI_Pre            347\nonset_Median_Saccades_Start_In_RoI_Pre          347\ndtype: int64"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.isna().sum(axis=0).sort_values(ascending=False).head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:48.722410300Z",
     "start_time": "2023-08-14T12:29:48.698473800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove columns with more than 30% missing values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "features_df = features_df.loc[:, features_df.isna().sum(axis=0) < 0.3 * features_df.shape[0]]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:48.784248200Z",
     "start_time": "2023-08-14T12:29:48.715431100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "Pupil radius_Fixations_ReEntry_Mean_Diff_Pre    460\nPupil radius_Fixations_First_Diff_Pre           460\nBlinks_Duration_Max                             397\nBlinks_Duration_Mean                            397\nBlinks_Per_Minute                               397\nBlinks_Duration_Min                             397\nBlinks_Duration_Median                          397\nBlink_Variability                               397\nonset_Mean_Saccades_Start_In_RoI_Pre            347\nonset_Median_Saccades_Start_In_RoI_Pre          347\ndtype: int64"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.isna().sum(axis=0).sort_values(ascending=False).head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:48.797741400Z",
     "start_time": "2023-08-14T12:29:48.731386500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "how many missing values are there in each row? show the top 10"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "1164    102\n496      49\n1706     49\n1452     49\n682      49\n1167     49\n1789     49\n1290     49\n890      49\n1761     49\ndtype: int64"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.isna().sum(axis=1).sort_values(ascending=False).head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:48.798739Z",
     "start_time": "2023-08-14T12:29:48.746347400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove rows with more than 50% missing values"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "features_df = features_df.loc[features_df.isna().sum(axis=1) < 0.5 * features_df.shape[1], :]\n",
    "# remove the corresponding rows from y_train\n",
    "labels_df = labels_df.loc[labels_df.index.isin(features_df.index)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:48.799735500Z",
     "start_time": "2023-08-14T12:29:48.761314100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "1033    49\n1257    49\n1279    49\n1706    49\n1290    49\n319     49\n890     49\n1886    49\n1317    49\n1111    49\ndtype: int64"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_df.isna().sum(axis=1).sort_values(ascending=False).head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:48.802732Z",
     "start_time": "2023-08-14T12:29:48.778266900Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Train/Test Split (before any preprocessing is done)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "series_id_df = pd.read_pickle(os.path.join(config.classification_resource_dir, \"memory_series_id_df.pkl\"))\n",
    "\n",
    "# Create a list of unique subject IDs\n",
    "subject_ids = series_id_df[config.SUBJECT].unique()\n",
    "\n",
    "# Shuffle the list of subject IDs randomly\n",
    "random = np.random\n",
    "random.seed(1)\n",
    "random.shuffle(subject_ids)\n",
    "\n",
    "# Split the list of subject IDs into two parts\n",
    "train_subject_ids = subject_ids[:int(len(subject_ids)*0.9)]\n",
    "print(len(train_subject_ids))\n",
    "test_subject_ids = subject_ids[int(len(subject_ids)*0.9):]\n",
    "print(len(test_subject_ids))\n",
    "\n",
    "# Subset the data based on the split list of subject IDs\n",
    "train_data = series_id_df[series_id_df[config.SUBJECT].isin(train_subject_ids)]\n",
    "test_data = series_id_df[series_id_df[config.SUBJECT].isin(test_subject_ids)]\n",
    "\n",
    "X_train = features_df[features_df.index.isin(train_data.index)]\n",
    "X_test = features_df[features_df.index.isin(test_data.index)]\n",
    "y_train = labels_df[labels_df.index.isin(train_data.index)]\n",
    "y_test = labels_df[labels_df.index.isin(test_data.index)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:48.842619700Z",
     "start_time": "2023-08-14T12:29:48.794230900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "#\n",
    "# X_train, X_test, y_train, y_test = train_test_split(features_df,\n",
    "#                                                     labels_df['mem'],\n",
    "#                                                     random_state=420,\n",
    "#                                                     test_size=0.2)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:48.854589800Z",
     "start_time": "2023-08-14T12:29:48.807714Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "data": {
      "text/plain": "   Blinks_Per_Minute  Blinks_Duration_Mean  Blinks_Duration_Median  \\\n0          12.342857            132.000000                   129.0   \n1                NaN                   NaN                     NaN   \n2          27.692308            130.000000                    86.0   \n3          12.378223             72.666667                    66.0   \n4          14.400000             79.000000                    80.0   \n\n   Blink_Variability  Blinks_Duration_Min  Blinks_Duration_Max  \\\n0          67.549981                 66.0                201.0   \n1                NaN                  NaN                  NaN   \n2         104.115321                 64.0                312.0   \n3          24.684678                 52.0                100.0   \n4          26.514147                 52.0                105.0   \n\n   Fixations_Count  Fixations_Rate  Fixations_Duration_Mean  \\\n0             35.0        2.400000               333.771429   \n1             46.0        3.154286               284.608696   \n2             30.0        2.769231               321.066667   \n3             52.0        3.575931               244.423077   \n4             25.0        2.000000               308.080000   \n\n   Fixations_Duration_Median  ...  DVA_Min_Gaze_Pre  DVA_Sem_Gaze_Pre  \\\n0                      275.0  ...          9.485436          0.114942   \n1                      267.0  ...          2.614537          0.113426   \n2                      264.0  ...          5.844040          0.128652   \n3                      217.0  ...         11.783918          0.042936   \n4                      223.0  ...          0.581440          0.076724   \n\n   DVA_AUC_Gaze_Pre  DVA_Mean_Fixations_Pre  DVA_Median_Fixations_Pre  \\\n0      52474.278127               19.743823                 24.670071   \n1      62010.907977               19.295206                 22.554525   \n2      36331.111637               16.405096                 16.357059   \n3      62956.761877               19.795590                 20.467621   \n4      64937.572461               15.083811                 16.300744   \n\n   DVA_Std_Fixations_Pre  DVA_Max_Fixations_Pre  DVA_Min_Fixations_Pre  \\\n0               6.053553              25.457728               9.789465   \n1               6.835452              25.391660               3.181130   \n2               6.786038              25.893978               6.629466   \n3               2.385218              24.389404              16.085974   \n4               5.101190              22.310018               1.558471   \n\n   DVA_Sem_Fixations_Pre  DVA_AUC_Fixations_Pre  \n0               1.563021             296.157339  \n1               1.528453             385.904129  \n2               1.813645             229.671346  \n3               0.459035             534.480926  \n4               1.087577             331.843843  \n\n[5 rows x 102 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Blinks_Per_Minute</th>\n      <th>Blinks_Duration_Mean</th>\n      <th>Blinks_Duration_Median</th>\n      <th>Blink_Variability</th>\n      <th>Blinks_Duration_Min</th>\n      <th>Blinks_Duration_Max</th>\n      <th>Fixations_Count</th>\n      <th>Fixations_Rate</th>\n      <th>Fixations_Duration_Mean</th>\n      <th>Fixations_Duration_Median</th>\n      <th>...</th>\n      <th>DVA_Min_Gaze_Pre</th>\n      <th>DVA_Sem_Gaze_Pre</th>\n      <th>DVA_AUC_Gaze_Pre</th>\n      <th>DVA_Mean_Fixations_Pre</th>\n      <th>DVA_Median_Fixations_Pre</th>\n      <th>DVA_Std_Fixations_Pre</th>\n      <th>DVA_Max_Fixations_Pre</th>\n      <th>DVA_Min_Fixations_Pre</th>\n      <th>DVA_Sem_Fixations_Pre</th>\n      <th>DVA_AUC_Fixations_Pre</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>12.342857</td>\n      <td>132.000000</td>\n      <td>129.0</td>\n      <td>67.549981</td>\n      <td>66.0</td>\n      <td>201.0</td>\n      <td>35.0</td>\n      <td>2.400000</td>\n      <td>333.771429</td>\n      <td>275.0</td>\n      <td>...</td>\n      <td>9.485436</td>\n      <td>0.114942</td>\n      <td>52474.278127</td>\n      <td>19.743823</td>\n      <td>24.670071</td>\n      <td>6.053553</td>\n      <td>25.457728</td>\n      <td>9.789465</td>\n      <td>1.563021</td>\n      <td>296.157339</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>46.0</td>\n      <td>3.154286</td>\n      <td>284.608696</td>\n      <td>267.0</td>\n      <td>...</td>\n      <td>2.614537</td>\n      <td>0.113426</td>\n      <td>62010.907977</td>\n      <td>19.295206</td>\n      <td>22.554525</td>\n      <td>6.835452</td>\n      <td>25.391660</td>\n      <td>3.181130</td>\n      <td>1.528453</td>\n      <td>385.904129</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>27.692308</td>\n      <td>130.000000</td>\n      <td>86.0</td>\n      <td>104.115321</td>\n      <td>64.0</td>\n      <td>312.0</td>\n      <td>30.0</td>\n      <td>2.769231</td>\n      <td>321.066667</td>\n      <td>264.0</td>\n      <td>...</td>\n      <td>5.844040</td>\n      <td>0.128652</td>\n      <td>36331.111637</td>\n      <td>16.405096</td>\n      <td>16.357059</td>\n      <td>6.786038</td>\n      <td>25.893978</td>\n      <td>6.629466</td>\n      <td>1.813645</td>\n      <td>229.671346</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>12.378223</td>\n      <td>72.666667</td>\n      <td>66.0</td>\n      <td>24.684678</td>\n      <td>52.0</td>\n      <td>100.0</td>\n      <td>52.0</td>\n      <td>3.575931</td>\n      <td>244.423077</td>\n      <td>217.0</td>\n      <td>...</td>\n      <td>11.783918</td>\n      <td>0.042936</td>\n      <td>62956.761877</td>\n      <td>19.795590</td>\n      <td>20.467621</td>\n      <td>2.385218</td>\n      <td>24.389404</td>\n      <td>16.085974</td>\n      <td>0.459035</td>\n      <td>534.480926</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>14.400000</td>\n      <td>79.000000</td>\n      <td>80.0</td>\n      <td>26.514147</td>\n      <td>52.0</td>\n      <td>105.0</td>\n      <td>25.0</td>\n      <td>2.000000</td>\n      <td>308.080000</td>\n      <td>223.0</td>\n      <td>...</td>\n      <td>0.581440</td>\n      <td>0.076724</td>\n      <td>64937.572461</td>\n      <td>15.083811</td>\n      <td>16.300744</td>\n      <td>5.101190</td>\n      <td>22.310018</td>\n      <td>1.558471</td>\n      <td>1.087577</td>\n      <td>331.843843</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 102 columns</p>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:48.858582800Z",
     "start_time": "2023-08-14T12:29:48.832647400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Fill missing values with the mean of the column"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "# fill inf values with the mean of the column\n",
    "X_train = X_train.replace([np.inf, -np.inf], np.nan)\n",
    "X_test = X_test.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "X_train = X_train.fillna(X_train.mean()) # fill missing values with the mean of the column or zero ? features_df.mean()\n",
    "X_test = X_test.fillna(X_train.mean())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:48.925920300Z",
     "start_time": "2023-08-14T12:29:48.839630100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove columns with low variance (threshold = 5%)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "# Create VarianceThreshold object with a variance with a threshold of 0.05\n",
    "thresholder = VarianceThreshold(threshold=0.05)\n",
    "\n",
    "# Fit the thresholder to the data\n",
    "thresholder.fit(X_train)\n",
    "\n",
    "# Get the indices of the columns that are retained\n",
    "feature_idx = thresholder.get_support(indices=True)\n",
    "\n",
    "# Create a list of the names of the retained columns\n",
    "feature_names = X_train.columns[feature_idx]\n",
    "\n",
    "# Subset the dataframe to include only the selected columns\n",
    "X_train = X_train[feature_names]\n",
    "X_test = X_test[feature_names]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:48.937885600Z",
     "start_time": "2023-08-14T12:29:48.905972100Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Remove highly correlated features"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [],
   "source": [
    "# Create correlation matrix\n",
    "corr_matrix = X_train.corr().abs()\n",
    "\n",
    "# Select upper triangle of correlation matrix\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool_))\n",
    "\n",
    "# Find index of feature columns with correlation greater than 0.95\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "\n",
    "# Drop features\n",
    "X_train.drop(to_drop, axis=1, inplace=True)\n",
    "X_test.drop(to_drop, axis=1, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:48.979774900Z",
     "start_time": "2023-08-14T12:29:48.933897400Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "How many features are left?"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "data": {
      "text/plain": "(1799, 67)"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:48.994738700Z",
     "start_time": "2023-08-14T12:29:48.981772600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Balancing the dataset"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [
    {
     "data": {
      "text/plain": "mem\n1      1327\n0       472\ndtype: int64"
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:49.012204700Z",
     "start_time": "2023-08-14T12:29:48.994738700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "SMOTE"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# from imblearn.over_sampling import SMOTE\n",
    "# \n",
    "# sm = SMOTE(random_state=420)\n",
    "# X_train, y_train = sm.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:49.025176300Z",
     "start_time": "2023-08-14T12:29:49.010211Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Random Oversampling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "ros = RandomOverSampler(random_state=420)\n",
    "X_train, y_train = ros.fit_resample(X_train, y_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:49.118462300Z",
     "start_time": "2023-08-14T12:29:49.026168Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "mem\n0      1327\n1      1327\ndtype: int64"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:49.137412500Z",
     "start_time": "2023-08-14T12:29:49.122450800Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Scaling"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Create separate StandardScaler instances\n",
    "scaler_x = StandardScaler()\n",
    "# scaler_y = StandardScaler()\n",
    "\n",
    "# Fit on Training Data (!)\n",
    "scaler_x.fit(X_train.values)\n",
    "# scaler_y.fit(y_train.values.reshape(-1, 1))\n",
    "\n",
    "# Transform both training and testing data\n",
    "X_train_scaled = scaler_x.transform(X_train.values)\n",
    "X_test_scaled = scaler_x.transform(X_test.values)\n",
    "y_train = y_train.values.reshape(-1, 1).flatten()\n",
    "y_test = y_test.values.reshape(-1, 1).flatten()\n",
    "\n",
    "X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:49.150380800Z",
     "start_time": "2023-08-14T12:29:49.137412500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "PCA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca = PCA(n_components=0.95).fit(X_train_scaled)\n",
    "plt.plot(np.cumsum(pca.explained_variance_ratio_))\n",
    "plt.xlabel('number of components')\n",
    "plt.ylabel('cumulative explained variance');"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:49.280601800Z",
     "start_time": "2023-08-14T12:29:49.151374500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "X_train_pca = pca.transform(X_train_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:49.308008200Z",
     "start_time": "2023-08-14T12:29:49.279566500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "data": {
      "text/plain": "array([[-6.96168959e-01, -2.62422548e-03,  9.50017742e-01, ...,\n         3.55081974e-01, -1.62624675e-01,  6.66426802e-02],\n       [ 2.01488361e+00, -3.90594937e+00,  3.22964121e+00, ...,\n        -1.08185813e+00, -1.55853959e-01,  4.27180208e-01],\n       [-3.27101347e+00,  1.86368518e+00,  1.02200505e+00, ...,\n         1.02469867e-01, -2.17547365e-01,  1.70569487e-01],\n       ...,\n       [-3.91477396e+00,  2.19873329e+00,  2.44557580e-01, ...,\n        -1.96828250e-01, -7.16317757e-02,  5.98017545e-02],\n       [ 2.51388415e+00, -5.85628089e+00,  3.49224301e+00, ...,\n        -1.23454867e+00, -4.22060634e-01,  6.52337045e-01],\n       [-3.34433820e+00,  2.94395778e+00,  6.41470195e-01, ...,\n         1.58337641e-01, -1.66964967e-01,  1.65357452e-01]])"
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_pca"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:49.312Z",
     "start_time": "2023-08-14T12:29:49.295529Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "LDA"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=1)\n",
    "X_train_lda = lda.fit_transform(X_train_scaled, y_train)\n",
    "X_test_lda = lda.transform(X_test_scaled)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:49.368845200Z",
     "start_time": "2023-08-14T12:29:49.310002900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAESCAYAAAAR2wXeAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAApUElEQVR4nO3ceXwUVb738U/1lq1DQiAsikFAA6JiAFEYDQwiAyK4IbI4jIziy/FxGcWLODOPXIdRlqvMqjIjjqjc0YCICi6jIigjF30gEhERkAgIiJAAIelsvVQ9f1R1kxDCEr0Ttb7v1ysv0lV1Tv3qdOfbp063GpZlWYiIiCt4mrsAERH591Hoi4i4iEJfRMRFFPoiIi6i0BcRcRGFvoiIiyj05Ttj165d9OzZ86j7/vKXv9C3b1+uvPJKrrzySi6//HImTZrE9u3bGxx7xx13cOGFF1JdXd3ouYqKihg/fjwjRoxg+PDhTJw4kc8//7zJta9fv56pU6cmHt94440cOHCgyf0B3HfffeTn53PllVdy1VVXMXz4cG699Vb2798PwCWXXMInn3xyUnWJKPTle2PYsGG88sorvPLKK7z22mv079+fG264gVAolDhm7969rFmzhry8PF5++eWj9hMOh7nlllu47777WLp0Ka+++iojRozg5ptvJhaLNam2rVu3snfv3sTjVatWNamfI02YMIFXXnmFl19+mVdffZWOHTvy29/+tsl1ifiauwCRprrqqqtYsmQJS5cuZezYsQAsXLiQfv36MWTIEP70pz8xZswYDMOo1666upqKigqqqqoS26644gqCwSCxWAyv18uiRYuYN28eHo+Hli1bMmvWLNq2bcv06dP5+OOPqaysxLIsHnzwQU455RT+/Oc/U1FRwa9+9atEnzfccANPPPEEHo+HadOmsWfPHiKRCJdffjm/+MUv2LVrF9dffz1dunRh9+7dzJ8/nzZt2hzzmvv168fDDz/cYPuCBQuYP38+Ho+H1q1bc//995OcnFyvrhkzZnyT4ZYfCIW+fK917dqVLVu2ABCNRlm4cCHTpk3joosuYurUqaxcuZIBAwbUa5ORkcHkyZOZOHEirVu3plevXlx44YVcfvnlBAIBNm3axCOPPMJLL71E+/btefrpp5kzZw5XX301+/btY8GCBXg8Hp544gnmzp3LX//6V+68807efPPNRLAuXryYZ555hqysLH72s58xYcIELrnkEmpra7n55pvJycmhR48efP3118yePZvzzz//uNdaU1PDyy+/zIUXXlhv++rVq3nyySdZsGABWVlZLF68mNtuu43XXnutQV0iCn35XjMMg+TkZADeeecdTNMkPz8fn8/HsGHDePbZZxuEPsDPf/5zRo0axZo1a1izZg1z585l7ty5LFq0iNWrV3PxxRfTvn17wF5iicvIyKCgoICdO3fy4YcfkpaWdsz6qqqqWLNmDYcOHeJPf/pTYtumTZvo0aMHPp+PvLy8Rts//fTTLFmyBIBYLEafPn2YNGlSvWP+9a9/MWzYMLKysgC45ppreOihh9i1a9exB09cSaEv32uffPIJI0eOBOC5556jpqaGn/zkJ4C9dl9SUsLnn3/OmWeemWhTWFjIunXrmDhxIgMHDmTgwIFMmjSJ4cOHs2rVKrxeb70loZqaGnbv3s3OnTt56KGH+PnPf86gQYPo3LlzIpAbY5omlmVRUFBASkoKAAcOHCApKYmDBw8SCATw+Rr/M5wwYQI33XTTcc9xJMuyiEajx2wn7qQPcuV764UXXmDXrl1cdtllbNu2jTVr1rB48WKWL1/O8uXLef/99+nTpw/PPvtsvXZZWVnMmTOHtWvXJraVlJQQCoXIzc3lwgsvZPXq1ezbtw+AgoICHn74YVatWsXAgQMZN24c55xzDsuWLUt88Ov1euuFbPxxMBgkLy+PefPmAVBeXs7YsWN55513vrVxyM/P5/XXX098W+jFF18kMzOTjh07NqhLRDN9+U6pqqpq8LXNgoICAF5//XUKCwsxDAPTNOnUqRPPPvssSUlJPP/881x66aV07NixXtvbbruNW265hbvvvjux/NGpUycee+wx/vCHP/D111+TlJREeno606dPp3PnzgCJNX+A7Oxspk+fTigU4p577mHEiBFEo1Euuugi3nrrLUzTJC8vj8cee4zbb7+dRx99lKFDhzJ+/Hj+8pe/8Mgjj/C73/2OESNGEA6HGT58OFdcccW3tvxy0UUXMWHCBG644QZM0yQrK4u//e1veDyeBnWJGPpfK4uIuIeWd0REXEShLyLiIgp9EREXUeiLiLjId/7bO6ZpEovps+Y4r9fQeNSh8WhIY1KfW8fD7/cedft3PvRjMYuysqrjH+gSmZmpGo86NB4NaUzqc+t4ZGenH3W7lndERFxEoS8i4iIKfRERF1Hoi4i4iEJfRMRFFPoiIi6i0BcRcRGFvoiIiyj0RURcRKEvIuIiCn0RERdR6IuIuIhCX0TERRT6IiIuotAXEXERhb6IiIso9EVEXEShLyLiIgp9EREXUeiLiLiIQl9ExEUU+iIiLqLQFxFxEYW+iIiLKPRFRFykSaFvmiZTp05l9OjRjB8/nh07dtTbv3z5ckaOHMno0aNZuHBhvX379+9nwIABFBcXN71qERFpkiaF/rJlywiHwyxYsIB77rmHmTNnJvZFIhFmzJjBU089xfz581mwYAElJSWJfVOnTiU5OfnbqV5ERE5Kk0K/sLCQ/Px8APLy8tiwYUNiX3FxMTk5OWRkZBAIBOjduzdr164FYNasWYwZM4Y2bdp8C6WLiMjJ8jWlUSgUIhgMJh57vV6i0Sg+n49QKER6enpiX1paGqFQiMWLF5OVlUV+fj5PPPHECZ/L6zXIzExtSpk/SF6vR+NRh8ajIY1JfRqP+poU+sFgkMrKysRj0zTx+XxH3VdZWUl6ejrz58/HMAxWr17NZ599xpQpU5gzZw7Z2dnHPFcsZlFWVtWUMn+QMjNTNR51aDwa0pjU59bxyM5OP+r2JoV+r169WLFiBcOGDaOoqIjc3NzEvi5durBjxw7KyspITU1l7dq13HTTTQwdOjRxzPjx43nggQeOG/giIvLtalLoDx48mFWrVjFmzBgsy2L69OksXbqUqqoqRo8ezX333cdNN92EZVmMHDmStm3bftt1i4hIExiWZVnNXcSxRCIxV96aNcatt6qN0Xg0pDGpz63j0djyjv7jLBERF1Hoi4i4iEJfRMRFFPoiIi6i0BcRcRGFvoiIiyj0RURcRKEvIuIiCn0RERdR6IuIuIhCX0TERRT6IiIuotAXEXERhb6IiIso9EVEXEShLyLiIgp9EREXUeiLiLiIQl9ExEUU+iIiLqLQFxFxEYW+iIiLKPRFRFxEoS8i4iIKfRERF1Hoi4i4iEJfRMRFFPoiIi6i0BcRcRGFvoiIiyj0RURcRKEvIuIivqY0Mk2TBx54gM2bNxMIBHjwwQfp2LFjYv/y5ct57LHH8Pl8jBw5kuuuu45IJMKvf/1rdu/eTTgc5tZbb2XQoEHf2oWIiMjxNSn0ly1bRjgcZsGCBRQVFTFz5kzmzJkDQCQSYcaMGSxatIiUlBTGjh3LwIEDWblyJZmZmTz88MMcPHiQq6++WqEvIvJv1qTQLywsJD8/H4C8vDw2bNiQ2FdcXExOTg4ZGRkA9O7dm7Vr1zJ06FCGDBmSOM7r9X6TukVEpAmaFPqhUIhgMJh47PV6iUaj+Hw+QqEQ6enpiX1paWmEQiHS0tISbe+8807uuuuuEzqX12uQmZnalDJ/kLxej8ajDo1HQxqT+jQe9TUp9IPBIJWVlYnHpmni8/mOuq+ysjLxJrBnzx5uu+02xo0bx4gRI07oXLGYRVlZVVPK/EHKzEzVeNSh8WhIY1KfW8cjOzv9qNub9O2dXr16sXLlSgCKiorIzc1N7OvSpQs7duygrKyMcDjM2rVr6dmzJ6Wlpdx4441MnjyZa6+9timnFRGRb8iwLMs62Ubxb+9s2bIFy7KYPn06GzdupKqqitGjRye+vWNZFiNHjuT666/nwQcf5I033qBz586JfubOnUtycvIxzxWJxFz5Lt0Yt85aGqPxaEhjUp9bx6OxmX6TQv/fSaFfn1tfwI3ReDSkManPrePxrS7viIjI95NCX0TERRT6IiIuotAXEXERhb6IiIso9EVEXEShLyLiIgp9EREXUeiLiLiIQl9ExEUU+iIiLqLQFxFxEYW+iIiLKPRFRFxEoS8i4iIKfRERF1Hoi4i4iEJfRMRFFPoiIi6i0BcRcRGFvoiIiyj0RURcRKEvIuIiCn0RERdR6IuIuIhCX0TERRT6IiIuotAXEXERhb6IiIso9EVEXMTX3AX8b9i2DZYu9eP3w7XXRsjOPvG2+/cbfPyxh127DFq1suja1aRLFwvDaLxNOAwffeThuef8lJcbDBgQZfz4KCtWeHnjDS+pqVBcbFBU5CUYNDnjDPjqK4PWrU3atoXUVIu1a+Hzz32ARcuWBunpFocO2fVYFng8YBjg9QKkkpJiEQxCWZmBadp9VFcbxGKQkWESiRgcOmTv++FLbe4C/lf4/RCJ1N+Wnm6/Fqqr7dcd2K+LjAyLtm0t9u41qKiApKRUTj89wvbtfiIRyM626NEjRlGRj9paizPOiJGa6iEchljMIikJLr88Rrt2Ji++GODAAcjMNDEMD2eeGSMQgJ07PZx5pknXrjEefTRAKGQwYECEiy6yaNnSpKDAx9q1PtLSLHr0MAkGLTwe6NHDZPDgGCUlBhs3ekhNhfR0k7ff9pGSAqNGRcjKsq8lHIbCQg+rV3spLzdISwOv16J9e4vBg2MEgxZFRV6qquDss03Ky2HlSi9lZQatW1t062bSs6dJIHD0MQ2FYN06L6YJeXkxMjKa/vxEo7B+vYeyMoMuXUw6drROuo9QCIqKvESjcN55MVq2tPstKvJQXm6Qm2vSocPJ93sshmVZJ92jaZo88MADbN68mUAgwIMPPkjHjh0T+5cvX85jjz2Gz+dj5MiRXHfddcdt05hIJEZZWdUJ1/bQtAAvPeWnowVRA3Z74T8eqmXMmOhx276+xOLFP5cQ+rKM1uGvaG/s5etTe9Hp0o7c8evAUV9IO3YYTL49mfVrvGSZkA3sAQ56LFqbxXRnPSu4miwMTgW+AkJAZ6AUOAREgBQgHagBWjv/7gX8gBdo5fxeAkSBWuf4ts62cuBU59ivgJhTXwcgCdgKWM4xqcA2p48zsW/3tjl9pAKZzrGtnG0lzvbTgC+d2joAQaddBdASyAHKnOtvDVQ6Py2A9s7v+5yao8DX2LOO5DrbdgNhZzxwzlntbPc5dbRz+jrobDvk1ORx2p3m9PmlMw4+53osZ3xSnHoPOX3UAAEgw6kppc647XLaB4EDQBvn33LgFKef3c62+LjFZ1LZztjsBbKc/kud2iqd6/I7dacDVc64Wc5z6HHGtNLpJwCUYJFOlE7UEMJDiBB9eJd1nMc+2hIgndOx+BofEQxOw6KKGDswSMabeN2VAadhAQa7gWzCRDGoIsRlvMAmzmInp3EBH5JNKR/QlzRC7KcluzmXDhi0cJ7/KmpJoYRUasiggl58hImHj+iFZXhJC0Qoz+hA1zb76edby4pduXx5oAWDAiup9SSz2ncxt846hd69Yzx0d4gvPirn9JrNtLO+4lPOJkAET8DHvvROtGoNF6UW0cIs4+VdfSirTqJzZDMdo8Vs83ShOrM9bc9pxeRHMhIhnJmZSllZFR9+6OHp35XQI1KIlygfec5n9H+0ZeCgkw/VvXsNHp5SQdaejXSwdrGOPM4cfBq3TPI7E7PjK1zr4cnflnJueC1+InzkOZ8fj2/H6tfKOaV0A+2sPRTSix5XdODG23zHnHgeTXZ2+lG3N2mmv2zZMsLhMAsWLKCoqIiZM2cyZ84cACKRCDNmzGDRokWkpKQwduxYBg4cyLp16xpt82354AMPS/4e4KfJFhnOwO8KwyO/SWLQoOgxZ/zbthm8+eh2zjpYxNnmB1yf+gKhWAqb9nXltfdu5rVzLuPqa+u/OCwLHpmWxLZ1HvJMyMeedVVbsNyEFPaymoGchcFl2H/8PYGd2KHxU+Bd4BNgMLAFuBQ79EqwQ+Ad4CfY4ZLu7FsAdAG6AyaHQzseEgawGLgCO6QM53xnY7/ZeIBOwHrsmjOxQ6sAO+jaOnWAHeB7nNq7Yb95XOa0N5zatzr1Z2IH1ifAKiDN2TYYO2yj2EH3AfBjYB12yF6L/cZQ7pznTewwvBY78Mqd604ChmOHXxWwA9jk1LLOOcdw7MD2YYf5Iuxw3u/U0xLo5ewvdfrY6vRd6hzzE+B07DeES4C3nPFuA6wEhgIfAx2Bc5xa3nZqPw87UC9xnpsD2M93MXABdqi/DVzo/BsELgI+cmpPwn5jjAJrgHOx36i3O487YXAePk7lINmUUkKMLWRQRQpppHI95XyFHwgyEDiIgZ8a3iTIxUAWJm/hYShQiUEq4MPinwS4jF142cc+WnMGW7iBZ+jLh5zOdg6QyWT+i8/oxxAsujrjbY9xEofwczbrmMJMzmYjydSwiW78xppOy2g5tfu+oH9sAz/q+CUfHkhjsXEDVbEWnBvcTmH4XG6e8iTn9E3G3LiFibUvMchYRrpVTjb7+L88RE5kF4UHzyer4hD39FlKeRnsqziAL1LDGKOAc32fUWv6+X35ZCq2d+HxaQOZ+WQwEZTl5fD07/bxYOC3dMrca7+2a1/h3ocfoPs5p9C27ckF/9z/qmTEnicZkf0/AITNRUz7560sP+/HDP5J7Dit7Rn+k78tYZp/Gl0y9gCwt+YVxv72fm7usJSx7d8FoCb2Ive//Ev+1aMf/fsfv98T0aQ1/cLCQvLz8wHIy8tjw4YNiX3FxcXk5OSQkZFBIBCgd+/erF279phtvi0Fz/npzuHAB+gQgFNjsHix/5htV6+0uCS2jK2H2jLSvwSAoLeaDLOMoZ43+WBpWYM2O3YY7N/hoSpscAEkXmA+oBcxdnA2UVrSB3uga7FD5xzssLOAPOw/nj3YoRrADgI/9ky7ldMuxdkWdI7v7tQQcH56YYdLAHt2eip2ePuwZ6LtsMOwFjuUWgNdsWfDYM9Eu2EHTjcO32GkOW3jAZ+FfXdgcviuoif2jNpyrrO7U2/M6SsFOxgzsIMzPjtu5dTUwqkh6Jyvo1NfwDnvfqdtV2ebB3u23AZ75n+KU0t77LCmTu3nYgf7edihfK7T3o8dsF2d4w9hvyHFr6/a6TsJOMsZl3jtJc54b3fqS3H6SXL2nVOnfx9wBvabVrVzfDfsN4F07LuBauy7k0ynnd/ZnuPU5Xf21zj1BzAIkU4b9nEWB9hDV2pJpRsxsomylRTOcepKAT4llXOder5wxreN8zj+OuuAxX4selDKDrpzkFaM51kqCBIgTAd2k8lBUvHTnRiG83wnY7+Go2QyiHfIZSseLJKp5Vw+IY8iDpnpDPX8k/XlnXh7V3dGsJQzPdvwWhFCsRR6Bz6hV/gDtmyIEq42uYIlVJsptONrkqllFAvZaJ3FlbxEpZnCwf0WJV+bFMc6caX1CtmU4sUkxVPL1eZCvq5Ix9i1m+3bD0+N16710jv8AZ1S9ya2tU86yIDoMj5YfXIxuH+/wZ5PDjCs9QeJbQFPlGvTXueDV8tOqI/CQi954TV0Sd2T2JZBGQNrXrdnk45kb4Rrkl/jgzfKT6rGY2nSTD8UChEMBhOPvV4v0WgUn89HKBQiPf3wbUVaWhqhUOiYbY7F6zXIzDyxNVsPBn4MjCOeQx9gGH4yMxsP/oAvTLInigEEPDE8ToJ7DYtUbxTwNKgjJQWSvJ7EOeryY2HixThin4EdSGAHZ3xfrM72+HHxfo+cg8SXKaLOcfFzmM7v8SWNuPh5PE4bq06bukvG8dE5sl6c80WcfXXvMuN9W0e0iZ8r3pdF/WuK19rYNZt1tll1tnPE8XXbH1lb3b7iNdat52h/6vE+jlYvzvni/cWOaBdfQjra+HmcdvH98TdNb53fj7y2I8fB4xxnJLZZGBh4MI54LRmJ3406/du/198XH1t/nXN5AA8xvM4VHn5uPYnlqLofFfkBAw8Bwk4lhyVRi9eK4jNixPBiWj6SqAUDvJZ9n+rxGKQYNXiw8BPDg+lcm91XMjXE8JLi/OsxPFiYWHjwE8aDCYZ9PcmEieIj0x8lJSWFzEzwej0EAkmkecP4ffVHOtUTweMPkJl54msnNTWQ7DVJ8hkYxuH+0vwxjKPkxNEkJdGgnogXUo0aLCOl3vY0fwwP3hPOweNp0kw/GAxSWVmZeGyaZiK8j9xXWVlJenr6MdscSyxmUVZWdUI/g4bUsBGoiVlYpv1zMGyxA4vBg4/dtmsPk3fpT05wP8vCF2OaFtVRH2VWC96N/Ihz8tMatGnVqgojI0ay154FJ64N2ICPDmzGpJr12H84fuyliq3YM0o/9vJEfK39c6dtDXbA1mDPHIPYM8Wo86+JPVP0OI/DwEbsmW4Ye7a7E3sdOOZs3409W03Gnlkfcuro4NRc7dSSyeH1fwt7eeUQ9h1Cd+wlkPh6s+n0/Sn2DBynzXannce5phj2jDPkXP8+p13IqbPWaVvlXPd27Nk9TtsM59jPnf5N5zoPOrUdcLbHrzH+HESdcTnF+bcVsLnOtdVg3+l4nTEJONe3xxmnKqefzzm8Pl/i/L4BeyZuOTV/4ZyvlTOO8fNHnP7AvnPwYC/jdebwclYmhz8riTo/h7DvUDKcvkqwQ20zEMEihSoO0pKdBElnF8lUswkvVXjoSC2bnbGrAjpTy2dOLR2xEp/D1NQ5ZgcG2VhspwWZ7CKZGt5iCKlUEcXHQTKJ4OMgJtvxJt4ITGcsLMpZSX++oj0AYfzs5lTWcj5ej8Vqsy/dUrfTr91W3uAySs2W1BjJpHmr2BZuz2rPj2h7mg8zEOB942ICRpj9tMLE4FWGc4axlX8ylJaeMoIZ0Ko1nG5s511jIAdohWVBrennLc9QTgseoCS1A61b23+nsZhJbm41/zL7src6hUg0RiQa42CNn3f4Md3OqjnhjCkrqyIpqQr/qVn8a39uoq9wJMYrZfmc3T94Qn2ccUY1/2P2YU9V2uE+DB9ve4eS5qms1++SigGcnZ96UjUe63PQJn2Q++abb7JixQpmzpxJUVERjz76KE8++SRgr+lffvnlLFy4kNTUVMaMGcOcOXMoKipqtM2xnMwHuaYJt/w8mc/e9dHNgqhh8ZlhcNXEWn71fyPHbGtZ8NRjUQpf+JKynZWcH/t/tKaUbe0upPq8C/jN7FTq3MAkfPyxhyn/J5kdn3sS6747gW1YnMpn5FHIq4ynM3aw78IOprOw/+i3Y4deW+IzJvv3auxgj3/weCqHP5yswQ7V9s7PPuzA6+r0sR07JP3OeQJAEXZA5WK/iXyC/cfe2znHp9iBF8QOmhTnWg5hf17Qwmm7HjuUumMvn2x2zn8q9jJGmbOtJXbIlGMv1ZyOHTRf1rnWzc41BbGXHMLYARtytiVjr6VXOsf6sd8sc5y+djl17nPaGM55uztttzjnb+FcaxJ2SGU7x5U541bp7Mtynrt0Z9ziYxl1at7jjEkFh5fjWmOH8w7s8E7GDtK0OscWYy+RZXP4g3gLO/CTOPxGHF/miWG/iXicMa9yzpfq1NuaCN2p5BA+SjlEf5awih+xm46kk0Y3TD4nCR9wOhY1RCnCR0sMujvPwSFnbHHOlUWEZGA/ZYzmb2ykOxs5m2tYTBv28g6DCZHGIdLZSW/OdmreAnyFSSbbSaeG9nzNIJZhYfAWP6GCdNomHeRz71lcdNo2hgTeo2BbPw5WBRjpW0LUG2CRcR2Dbu/Mjy81+K+7D1D6+SH6R5bT1trDJ5zLflqT7T/I+qQ+ZARjXN/mLdJjZcz78lL21LQk33yPXHMTW40z2ZTWmxZnZnP7zGzy8uw7hfgHuUtfgmVztnOp+TY+oiwzBnP+9Z0ZO+Hk575btnj4872lXFC5nNPYxYdcQM3ZPZkyI4WUlOO3B3hjqcUbj+5ksPkmfiIsYzDtBpzBFx8e4OKat2nP16ziR3h6ncd//C6p0W8kNaaxD3K/0bd3tmzZgmVZTJ8+nY0bN1JVVcXo0aMT396xLIuRI0dy/fXXH7VNly5djnuuk/32jmnCG294eeNVH4EkuG5MhL59T+x7i5YFGzd6+PB9ky92+GjXKkKPPj769o0dc8BLSw1eWuxlwfN+aqugV1+Tu+6qZdEiP6uWRcBjsGlbCjVlBlGPRXrQ/mqR4YfWWRbeAGwtNoiGDWJAkgGGD2oj9u17/BYd6i+deLHqLPNYmHic5YIY4MFyFgI8HF6KiLePLzUYR+yPi/8ZmEdsi8+SPRxeSorzObUc+Xv82COXN+ouJ1Cn77rLDl7q10qd/fF6jnx248s+Ueov1dT911uvrYXXWUyIn7fu9cXPG28Xc3pqOAb2opWBkTjW7tNK9BlfXok6z5EnsT/+rHicc5nOb57E8kzMua/wY9jLHESxsJx5twef16Qm5sOHRQQfXq+FJ2ZgEsNLhLSsANWHvPZddopJRtBLJApmLExqip8+/WJkZFqsfS/MgXI/voBBalKMdu0tSPJTe6CWNjl+MlvBW2/4idQYdDwjxtXDa4h6fCx5EXZus/D5DTrkWLTI9JAWCNO9V4Cf3RDlyy89fLouRkq6h6oaD2vfj5Gc5mH0T6FXL/uZKC01+OfrBu++Y1B5KIqRlEQwOcwpp3m56lqLdu0sVq2E6kqLbud6KC01WPGWyYFSyGpjcH4fGDjIonXrw7EWD32A7dsNPlgFVszi/H72V1CbqqwM3v+Xh4P7YpzR3UefPjFOYPGinh07DD5YZRGLkKjn4EF4f6WHQ/tjdD3XS+/e5gl/I6iubzX0/51ONvR/6Oq+gEXjcTQak/rcOh6Nhb7+i1wRERdR6IuIuIhCX0TERRT6IiIuotAXEXERhb6IiIso9EVEXEShLyLiIgp9EREXUeiLiLiIQl9ExEUU+iIiLqLQFxFxEYW+iIiLKPRFRFxEoS8i4iIKfRERF1Hoi4i4iEJfRMRFFPoiIi6i0BcRcRGFvoiIiyj0RURcRKEvIuIiCn0RERdR6IuIuIhCX0TERRT6IiIuotAXEXERhb6IiIso9EVEXEShLyLiIr6mNKqpqWHy5Mns37+ftLQ0Zs2aRVZWVr1jFi5cSEFBAT6fj1tvvZWBAwdSUVHB5MmTCYVCRCIR7rvvPnr27PmtXIiIiBxfk2b6zz//PLm5uTz33HNcddVVPP744/X2l5SUMH/+fAoKCvj73//O73//e8LhMPPmzaNv377893//NzNmzGDatGnfykWIiMiJadJMv7CwkIkTJwLQv3//BqG/fv16evbsSSAQIBAIkJOTw6ZNm5gwYQKBQACAWCxGUlLSNyxfREROxnFD/4UXXuCZZ56pt61Vq1akp6cDkJaWRkVFRb39oVAosT9+TCgUokWLFoB9JzB58mR+/etfH7dAr9cgMzP1+FfiEl6vR+NRh8ajIY1JfRqP+o4b+qNGjWLUqFH1tt1+++1UVlYCUFlZmQjzuGAwmNgfPyb+JrB582YmTZrEvffeywUXXHDcAmMxi7KyquNfiUtkZqZqPOrQeDSkManPreORnZ1+1O1NWtPv1asX7733HgArV66kd+/e9fb36NGDwsJCamtrqaiooLi4mNzcXLZu3covf/lLZs+ezYABA5pyahER+QYMy7Ksk21UXV3NlClTKCkpwe/3M3v2bLKzs5k3bx45OTkMGjSIhQsXsmDBAizL4pZbbmHIkCHceuutbN68mVNPPRWw7wjmzJlzzHNFIjFXvks3xq2zlsZoPBrSmNTn1vFobKbfpND/d1Lo1+fWF3BjNB4NaUzqc+t4fKvLOyIi8v2k0BcRcRGFvoiIiyj0RURcRKEvIuIiCn0RERdR6IuIuIhCX0TERRT6IiIuotAXEXERhb6IiIso9EVEXEShLyLiIgp9EREXUeiLiLiIQl9ExEUU+iIiLqLQFxFxEYW+iIiLKPRFRFxEoS8i4iIKfRERF1Hoi4i4iEJfRMRFFPoiIi6i0BcRcRGFvoiIiyj0RURcRKEvIuIiCn0RERdR6IuIuEiTQr+mpoY77riDcePGcfPNN3PgwIEGxyxcuJBrrrmG6667jhUrVtTbV1xcTO/evamtrW1a1SIi0iRNCv3nn3+e3NxcnnvuOa666ioef/zxevtLSkqYP38+BQUF/P3vf+f3v/894XAYgFAoxKxZswgEAt+8ehEROSlNCv3CwkLy8/MB6N+/P6tXr663f/369fTs2ZNAIEB6ejo5OTls2rQJy7K4//77mTRpEikpKd+8ehEROSm+4x3wwgsv8Mwzz9Tb1qpVK9LT0wFIS0ujoqKi3v5QKJTYHz8mFArx6KOPMmDAALp163bCBXq9BpmZqSd8/A+d1+vReNSh8WhIY1KfxqO+44b+qFGjGDVqVL1tt99+O5WVlQBUVlbSokWLevuDwWBif/yY9PR0lixZQrt27XjxxRcpKSnhxhtv5B//+Mcxzx+LWZSVVZ3wBf3QZWamajzq0Hg0pDGpz63jkZ2dftTtxw39o+nVqxfvvfcePXr0YOXKlfTu3bve/h49evDHP/6R2tpawuEwxcXF5Obm8vbbbyeOueSSS3jqqaeacnoREWmiJoX+2LFjmTJlCmPHjsXv9zN79mwA5s2bR05ODoMGDWL8+PGMGzcOy7K4++67SUpK+lYLFxGRk2dYlmU1dxHHEonEXHlr1hi33qo2RuPRkMakPreOR2PLO/qPs0REXEShLyLiIgp9EREXUeiLiLiIQl9ExEUU+iIiLqLQFxFxEYW+iIiLKPRFRFxEoS8i4iIKfRERF1Hoi4i4iEJfRMRFFPoiIi6i0BcRcRGFvoiIiyj0RURcRKEvIuIiCn0RERdR6IuIuIhCX0TERRT6IiIuotAXEXERhb6IiIso9EVEXMSwLMtq7iJEROTfQzN9EREXUeiLiLiIQl9ExEUU+iIiLqLQFxFxEYW+iIiLKPRFRFxEof89U1FRwS9+8Qt++tOfMnr0aNatW9fcJTUL0zSZOnUqo0ePZvz48ezYsaO5S2pWkUiEyZMnM27cOK699lreeeed5i7pO2P//v0MGDCA4uLi5i7lO8HX3AXIyZk3bx59+/ZlwoQJfPHFF9xzzz289NJLzV3Wv92yZcsIh8MsWLCAoqIiZs6cyZw5c5q7rGazZMkSMjMzefjhhzl48CBXX301gwYNau6yml0kEmHq1KkkJyc3dynfGQr975kJEyYQCAQAiMViJCUlNXNFzaOwsJD8/HwA8vLy2LBhQzNX1LyGDh3KkCFDEo+9Xm8zVvPdMWvWLMaMGcMTTzzR3KV8Z2h55zvshRdeYPjw4fV+tm/fTnJyMiUlJUyePJlJkyY1d5nNIhQKEQwGE4+9Xi/RaLQZK2peaWlpBINBQqEQd955J3fddVdzl9TsFi9eTFZWVmJyIDbN9L/DRo0axahRoxps37x5M5MmTeLee+/lggsuaIbKml8wGKSysjLx2DRNfD53v5z37NnDbbfdxrhx4xgxYkRzl9PsXnzxRQzDYPXq1Xz22WdMmTKFOXPmkJ2d3dylNSt3/5V8D23dupVf/vKX/PGPf6Rbt27NXU6z6dWrFytWrGDYsGEUFRWRm5vb3CU1q9LSUm688UamTp1Kv379mruc74R//OMfid/Hjx/PAw884PrAB4X+987s2bMJh8M89NBDgD3jdeMHmIMHD2bVqlWMGTMGy7KYPn16c5fUrP76179SXl7O448/zuOPPw7A3Llz9QGmNKD/tbKIiIvog1wRERdR6IuIuIhCX0TERRT6IiIuotAXEXERfWVTpBEffvghBQUF/OEPf0hsGz9+PNXV1aSkpBCJROjQoQO/+c1vaNmyZeKY6dOn06lTJ8aOHdscZYsck2b6Iidp1qxZzJ8/n4KCAvr378/UqVMBOHDgABMnTmT58uXNXKFI4xT6It/AFVdcwaeffkptbS2VlZXccccdXHnllc1dlkijFPoi31CLFi0oLy/ntNNO47zzzmvuckSOSaEv8g1YlkVpaSmtWrVq7lJETohCX+QbWLRoEX379sXj0Z+SfD/o2zsix7Bq1SquueaaxON9+/YxZcoUUlJSAGjbti3/+Z//2VzliZw0/Q/XRERcRPekIiIuotAXEXERhb6IiIso9EVEXEShLyLiIgp9EREXUeiLiLjI/wf9zM3aJTbISgAAAABJRU5ErkJggg==\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create a scatter plot of the transformed data\n",
    "plt.scatter(X_train_lda, np.zeros(len(X_train_lda)), c=y_train, cmap='rainbow', alpha=0.7, edgecolors='b')\n",
    "plt.xlabel('LD1')\n",
    "plt.title('LDA Scatter Plot')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:49.523463600Z",
     "start_time": "2023-08-14T12:29:49.386801Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "X_train_preprocessed = X_train_scaled\n",
    "X_test_preprocessed = X_test_scaled"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:49.544407300Z",
     "start_time": "2023-08-14T12:29:49.523463600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Classification models"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "\n",
    "def evaluate_model(model_name, y_true, y_pred):\n",
    "    # Evaluate the model using various metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred)\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    print(model_name)\n",
    "    # Print the evaluation metrics\n",
    "    print(\"Accuracy:\", round(accuracy, 2))\n",
    "    print(\"Precision:\", round(precision, 2))\n",
    "    print(\"Recall:\", round(recall, 2))\n",
    "    print(\"F1-score:\", round(f1, 2))\n",
    "    print(\"ROC-AUC score:\", round(roc_auc, 2))\n",
    "\n",
    "    # Compute the confusion matrix\n",
    "    confusion_mat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    # Create a heatmap visualization of the confusion matrix\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    sns.heatmap(confusion_mat, annot=True, cmap=\"Blues\", fmt=\"d\", ax=ax)\n",
    "\n",
    "    # Set the axis labels and title\n",
    "    ax.set_xlabel(\"Predicted Labels\")\n",
    "    ax.set_ylabel(\"True Labels\")\n",
    "    ax.set_title(\"Confusion Matrix\")\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:49.559370800Z",
     "start_time": "2023-08-14T12:29:49.544407300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:29:49.571336600Z",
     "start_time": "2023-08-14T12:29:49.556377600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Logistic Regression model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_35388/1211400576.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     17\u001B[0m \u001B[1;31m# Use grid search and cross-validation to tune the hyper parameters\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     18\u001B[0m \u001B[0mmodel_searcher\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mGridSearchCV\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mestimator\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mPARAM_GRID\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 19\u001B[1;33m \u001B[0mmodel_searcher\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train_preprocessed\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     20\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     21\u001B[0m \u001B[1;31m# The best combination of hyperparameters\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, groups, **fit_params)\u001B[0m\n\u001B[0;32m    872\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mresults\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    873\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 874\u001B[1;33m             \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_run_search\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    875\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    876\u001B[0m             \u001B[1;31m# multimetric is determined here because in the case of a callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36m_run_search\u001B[1;34m(self, evaluate_candidates)\u001B[0m\n\u001B[0;32m   1386\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m_run_search\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1387\u001B[0m         \u001B[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1388\u001B[1;33m         \u001B[0mevaluate_candidates\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mParameterGrid\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mparam_grid\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1389\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1390\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001B[0m in \u001B[0;36mevaluate_candidates\u001B[1;34m(candidate_params, cv, more_results)\u001B[0m\n\u001B[0;32m    819\u001B[0m                     )\n\u001B[0;32m    820\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 821\u001B[1;33m                 out = parallel(\n\u001B[0m\u001B[0;32m    822\u001B[0m                     delayed(_fit_and_score)(\n\u001B[0;32m    823\u001B[0m                         \u001B[0mclone\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbase_estimator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m     61\u001B[0m             \u001B[1;32mfor\u001B[0m \u001B[0mdelayed_func\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[1;32min\u001B[0m \u001B[0miterable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     62\u001B[0m         )\n\u001B[1;32m---> 63\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__call__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterable_with_config\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     64\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     65\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, iterable)\u001B[0m\n\u001B[0;32m   1086\u001B[0m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_iterating\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_original_iterator\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1087\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1088\u001B[1;33m             \u001B[1;32mwhile\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdispatch_one_batch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1089\u001B[0m                 \u001B[1;32mpass\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1090\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36mdispatch_one_batch\u001B[1;34m(self, iterator)\u001B[0m\n\u001B[0;32m    899\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mFalse\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    900\u001B[0m             \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 901\u001B[1;33m                 \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_dispatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mtasks\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    902\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[1;32mTrue\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    903\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m_dispatch\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    817\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_lock\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    818\u001B[0m             \u001B[0mjob_idx\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlen\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 819\u001B[1;33m             \u001B[0mjob\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mbatch\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mcb\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    820\u001B[0m             \u001B[1;31m# A job can complete so quickly than its callback is\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    821\u001B[0m             \u001B[1;31m# called before we get here, causing self._jobs to\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36mapply_async\u001B[1;34m(self, func, callback)\u001B[0m\n\u001B[0;32m    206\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mapply_async\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mNone\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    207\u001B[0m         \u001B[1;34m\"\"\"Schedule a func to be run\"\"\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 208\u001B[1;33m         \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mImmediateResult\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mfunc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    209\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcallback\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    210\u001B[0m             \u001B[0mcallback\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mresult\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, batch)\u001B[0m\n\u001B[0;32m    595\u001B[0m         \u001B[1;31m# Don't delay the application, to avoid keeping the input\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    596\u001B[0m         \u001B[1;31m# arguments in memory\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 597\u001B[1;33m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresults\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mbatch\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    598\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    599\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0mget\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    286\u001B[0m         \u001B[1;31m# change the default number of processes to -1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    287\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 288\u001B[1;33m             return [func(*args, **kwargs)\n\u001B[0m\u001B[0;32m    289\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[0;32m    290\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001B[0m in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    286\u001B[0m         \u001B[1;31m# change the default number of processes to -1\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    287\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mparallel_backend\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_backend\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mn_jobs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_n_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 288\u001B[1;33m             return [func(*args, **kwargs)\n\u001B[0m\u001B[0;32m    289\u001B[0m                     for func, args, kwargs in self.items]\n\u001B[0;32m    290\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\parallel.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    121\u001B[0m             \u001B[0mconfig\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;33m{\u001B[0m\u001B[1;33m}\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    122\u001B[0m         \u001B[1;32mwith\u001B[0m \u001B[0mconfig_context\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m**\u001B[0m\u001B[0mconfig\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 123\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfunction\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001B[0m in \u001B[0;36m_fit_and_score\u001B[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001B[0m\n\u001B[0;32m    684\u001B[0m             \u001B[0mestimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfit_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    685\u001B[0m         \u001B[1;32melse\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 686\u001B[1;33m             \u001B[0mestimator\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mX_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0my_train\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mfit_params\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    687\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    688\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mException\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, X, y, sample_weight)\u001B[0m\n\u001B[0;32m   1214\u001B[0m                     \u001B[1;34m\" = {}.\"\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0meffective_n_jobs\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mn_jobs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1215\u001B[0m                 )\n\u001B[1;32m-> 1216\u001B[1;33m             self.coef_, self.intercept_, self.n_iter_ = _fit_liblinear(\n\u001B[0m\u001B[0;32m   1217\u001B[0m                 \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1218\u001B[0m                 \u001B[0my\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001B[0m in \u001B[0;36m_fit_liblinear\u001B[1;34m(X, y, C, fit_intercept, intercept_scaling, class_weight, penalty, dual, verbose, max_iter, tol, random_state, multi_class, loss, epsilon, sample_weight)\u001B[0m\n\u001B[0;32m   1222\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1223\u001B[0m     \u001B[0msolver_type\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0m_get_liblinear_solver_type\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmulti_class\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mpenalty\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdual\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1224\u001B[1;33m     raw_coef_, n_iter_ = liblinear.train_wrap(\n\u001B[0m\u001B[0;32m   1225\u001B[0m         \u001B[0mX\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1226\u001B[0m         \u001B[0my_ind\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Define the range of values for each hyperparameter\n",
    "C = np.linspace(0.01, 1, 15)\n",
    "PENALTY = ['l1', 'l2']\n",
    "SOLVER = ['liblinear', 'saga']\n",
    "\n",
    "PARAM_GRID  = {\n",
    "    'C': C,\n",
    "    'penalty': PENALTY,\n",
    "    'solver': SOLVER\n",
    "}\n",
    "\n",
    "# Create the logistic regression estimator\n",
    "estimator = LogisticRegression(random_state=420)\n",
    "\n",
    "# Use grid search and cross-validation to tune the hyper parameters\n",
    "model_searcher = GridSearchCV(estimator, PARAM_GRID, verbose=0)\n",
    "model_searcher.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# The best combination of hyperparameters\n",
    "model_searcher.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-08-14T12:30:21.083987500Z",
     "start_time": "2023-08-14T12:29:49.573331200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the best estimator\n",
    "log_reg_best_estimator = model_searcher.best_estimator_\n",
    "y_test_pred = log_reg_best_estimator.predict(X_test_preprocessed)\n",
    "\n",
    "evaluate_model(\"Logistic Regression (test data)\", y_test, y_test_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-08-14T12:30:21.083987500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Gradient Boosting model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Define the range of values for each hyperparameter\n",
    "LEARNING_RATE = np.linspace(0.01, 0.5, 10)\n",
    "MAX_DEPTH = range(2, 5)\n",
    "N_ESTIMATORS = range(100, 180, 15)\n",
    "\n",
    "\n",
    "PARAM_GRID  = {\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'max_depth': MAX_DEPTH,\n",
    "    'n_estimators': N_ESTIMATORS\n",
    "}\n",
    "\n",
    "# Create the gradient boosting estimator\n",
    "estimator = GradientBoostingClassifier(random_state=420)\n",
    "\n",
    "# Use grid search and cross-validation to tune the hyper parameters\n",
    "model_searcher = GridSearchCV(estimator, PARAM_GRID, verbose=0)\n",
    "model_searcher.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# The best combination of hyperparameters\n",
    "model_searcher.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2023-08-14T12:30:21.086980200Z",
     "start_time": "2023-08-14T12:30:21.085982600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Get the best estimator\n",
    "gb_best_estimator = model_searcher.best_estimator_\n",
    "y_test_pred = gb_best_estimator.predict(X_test_preprocessed)\n",
    "\n",
    "evaluate_model(\"Gradient Boosting (test data)\", y_test, y_test_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2023-08-14T12:30:21.085982600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Random Forest model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define the range of values for each hyperparameter\n",
    "N_ESTIMATORS = range(50, 140, 15)\n",
    "MAX_DEPTH = range(2, 6)\n",
    "MIN_SAMPLES_SPLIT = range(2, 4)\n",
    "MIN_SAMPLES_LEAF = range(1, 4)\n",
    "\n",
    "PARAM_GRID  = {\n",
    "    'n_estimators': N_ESTIMATORS,\n",
    "    'max_depth': MAX_DEPTH,\n",
    "    'min_samples_split': MIN_SAMPLES_SPLIT,\n",
    "    'min_samples_leaf': MIN_SAMPLES_LEAF\n",
    "}\n",
    "\n",
    "# Create the random forest estimator\n",
    "estimator = RandomForestClassifier(random_state=420)\n",
    "\n",
    "# Use grid search and cross-validation to tune the hyper parameters\n",
    "model_searcher = GridSearchCV(estimator, PARAM_GRID, verbose=0)\n",
    "model_searcher.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# The best combination of hyperparameters\n",
    "model_searcher.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2023-08-14T12:30:21.093960700Z",
     "start_time": "2023-08-14T12:30:21.087978100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "rf_best_estimator = model_searcher.best_estimator_\n",
    "y_test_pred = rf_best_estimator.predict(X_test_preprocessed)\n",
    "\n",
    "evaluate_model(\"Random Forest (test data)\", y_test, y_test_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2023-08-14T12:30:21.088975200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "XGBoost model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Define the range of values for each hyperparameter\n",
    "LEARNING_RATE = np.linspace(0.05, 0.5, 10)\n",
    "MAX_DEPTH = range(1, 5)\n",
    "N_ESTIMATORS = range(70, 150, 15)\n",
    "\n",
    "PARAM_GRID  = {\n",
    "    'learning_rate': LEARNING_RATE,\n",
    "    'max_depth': MAX_DEPTH,\n",
    "    'n_estimators': N_ESTIMATORS\n",
    "}\n",
    "\n",
    "# Define the ratio for scale_pos_weight\n",
    "ratio = float(np.sum(y_train == 0)) / np.sum(y_train == 1)\n",
    "\n",
    "# Create a XGBoost classifier with specific parameters\n",
    "estimator = XGBClassifier(objective='binary:logistic', scale_pos_weight=ratio)\n",
    "\n",
    "\n",
    "# Use grid search and cross-validation to tune the hyper parameters\n",
    "model_searcher = GridSearchCV(estimator, PARAM_GRID, verbose=0)\n",
    "model_searcher.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# The best combination of hyperparameters\n",
    "model_searcher.best_params_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2023-08-14T12:30:21.089971700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluate the best model on the test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "xgb_best_estimator = model_searcher.best_estimator_\n",
    "y_test_pred = xgb_best_estimator.predict(X_test_preprocessed)\n",
    "\n",
    "evaluate_model(\"XGBoost (test data)\", y_test, y_test_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2023-08-14T12:30:21.090969200Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "TabNetClassifier with automatic hyperparameters tuning"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install pytorch-tabnet\n",
    "!pip install optuna"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2023-08-14T12:30:21.092963500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert Pandas DataFrame to NumPy array\n",
    "X_train_np = X_train_preprocessed.values\n",
    "X_test_np = X_test_preprocessed.values"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2023-08-14T12:30:21.093960700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import torch\n",
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "import optuna\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Define objective function for optuna\n",
    "def objective(trial):\n",
    "    # Generate hyperparameter search space\n",
    "    params = {\n",
    "        'n_d': trial.suggest_int('n_d', 8, 64),\n",
    "        'n_a': trial.suggest_int('n_a', 8, 64),\n",
    "        'n_steps': trial.suggest_int('n_steps', 1, 19),\n",
    "        'gamma': trial.suggest_float('gamma', 0.1, 2.0),\n",
    "        'n_independent': trial.suggest_int('n_independent', 1, 10),\n",
    "        'n_shared': trial.suggest_int('n_shared', 1, 10),\n",
    "        'lambda_sparse': trial.suggest_float('lambda_sparse', 0.0001, 0.1),\n",
    "        # 'optimizer_fn': torch.optim.Adam,\n",
    "        # 'optimizer_params': dict(lr=2e-2, weight_decay=1e-5),\n",
    "        # 'mask_type': 'entmax',\n",
    "        # 'scheduler_params': dict(mode=\"min\", patience=5, min_lr=1e-5, factor=0.9,),\n",
    "        # 'scheduler_fn': torch.optim.lr_scheduler.ReduceLROnPlateau,\n",
    "        'verbose': 0\n",
    "    }\n",
    "\n",
    "    # Create TabNetClassifier object with hyperparameters from optuna\n",
    "    classifier = TabNetClassifier(**params)\n",
    "\n",
    "    # Train and evaluate the model\n",
    "    classifier.fit(X_train_np, y_train, eval_set=[(X_test_np, y_test)])\n",
    "    val_preds = classifier.predict_proba(X_test_np)[:, 1]\n",
    "    val_auc = roc_auc_score(y_test, val_preds)\n",
    "\n",
    "    return val_auc\n",
    "\n",
    "# Create optuna study\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "# Optimize hyperparameters using optuna\n",
    "study.optimize(objective, n_trials=42, timeout=600)\n",
    "\n",
    "# Get best hyperparameters from optuna\n",
    "best_params = study.best_trial.params\n",
    "\n",
    "# Train final model with best hyperparameters\n",
    "tabnet = TabNetClassifier(**best_params)\n",
    "tabnet.fit(X_train_np, y_train)\n",
    "best_params"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "end_time": "2023-08-14T12:30:21.184234900Z",
     "start_time": "2023-08-14T12:30:21.094958500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Evaluate the best model on the test data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Evaluate final model on test set\n",
    "y_test_pred = tabnet.predict(X_test_np)\n",
    "evaluate_model(\"Tabnet (test data)\", y_test, y_test_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2023-08-14T12:30:21.095958700Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The best model is Gradient Boosting"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "the_best_model_ever = tabnet"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2023-08-14T12:30:21.096954600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Feature importance"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(the_best_model_ever.feature_importances_,\n",
    "                                   index = X_train_preprocessed.columns,\n",
    "                                    columns=['importance']).sort_values('importance', ascending=False)\n",
    "feature_importances"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2023-08-14T12:30:21.097951600Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
